[2024-09-06 12:55:24,630] INFO Reading configuration from: D:\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 12:55:24,637] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 12:55:24,637] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 12:55:24,637] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 12:55:24,637] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 12:55:24,640] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-09-06 12:55:24,640] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-09-06 12:55:24,640] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-09-06 12:55:24,640] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-09-06 12:55:24,641] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-09-06 12:55:24,641] INFO Reading configuration from: D:\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 12:55:24,644] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 12:55:24,644] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 12:55:24,644] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 12:55:24,644] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 12:55:24,644] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-09-06 12:55:24,656] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@76908cc0 (org.apache.zookeeper.server.ServerMetrics)
[2024-09-06 12:55:24,658] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-09-06 12:55:24,659] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-09-06 12:55:24,661] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-09-06 12:55:24,671] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,671] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,673] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,675] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,678] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,678] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,678] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,679] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,679] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,680] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,683] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,683] INFO Server environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,683] INFO Server environment:java.version=19.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,684] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,684] INFO Server environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,684] INFO Server environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,685] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,685] INFO Server environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,686] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,686] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,686] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,687] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,691] INFO Server environment:user.name=Jerin.sam (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,692] INFO Server environment:user.home=C:\Users\jerin (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,692] INFO Server environment:user.dir=C:\Users\jerin (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,693] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,693] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,693] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,694] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,694] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,694] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,695] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,695] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,696] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,696] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,697] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-09-06 12:55:24,698] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,699] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,700] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-09-06 12:55:24,700] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-09-06 12:55:24,701] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 12:55:24,701] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 12:55:24,701] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 12:55:24,702] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 12:55:24,705] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 12:55:24,705] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 12:55:24,710] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,710] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,711] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-09-06 12:55:24,711] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-09-06 12:55:24,712] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir D:\kafka\__manual-logs__\zookeeper-logs\version-2 snapdir D:\kafka\__manual-logs__\zookeeper-logs\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,718] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-09-06 12:55:24,720] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-09-06 12:55:24,722] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-09-06 12:55:24,796] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-09-06 12:55:24,818] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-09-06 12:55:24,818] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-09-06 12:55:24,819] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-09-06 12:55:24,820] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-09-06 12:55:24,826] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-09-06 12:55:24,826] INFO Snapshotting: 0x0 to D:\kafka\__manual-logs__\zookeeper-logs\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-09-06 12:55:24,832] INFO Snapshot loaded in 12 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2024-09-06 12:55:24,833] INFO Snapshotting: 0x0 to D:\kafka\__manual-logs__\zookeeper-logs\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-09-06 12:55:24,835] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 12:55:24,844] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-09-06 12:55:24,844] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-09-06 12:55:24,862] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-09-06 12:55:24,863] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-09-06 12:55:54,889] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 12:55:55,180] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 12:55:55,183] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:55:55,287] INFO starting (kafka.server.KafkaServer)
[2024-09-06 12:55:55,288] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 12:55:55,303] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 12:55:55,308] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,308] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,308] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,311] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,311] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,312] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,313] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,313] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,314] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,314] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,315] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,315] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,315] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,316] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,316] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,317] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,317] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,317] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,320] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:55:55,360] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 12:55:55,368] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:55:55,370] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 12:55:55,371] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:55:55,375] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:52680, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:55:55,386] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-09-06 12:55:55,399] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10038ceb0f60000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:55:55,404] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 12:55:55,658] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 12:55:55,663] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:55:55,692] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:55:55,701] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server0-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 12:55:55,704] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:55:55,737] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:55:55,739] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:55:55,739] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:55:55,742] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:55:55,747] INFO [KafkaServer id=0] Rewriting D:\kafka\__manual-logs__\server0-logs\meta.properties (kafka.server.KafkaServer)
[2024-09-06 12:55:55,830] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 12:55:55,840] INFO No logs found to be loaded in D:\kafka\__manual-logs__\server0-logs (kafka.log.LogManager)
[2024-09-06 12:55:55,850] INFO Loaded 0 logs in 19ms (kafka.log.LogManager)
[2024-09-06 12:55:55,852] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 12:55:55,854] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 12:55:55,933] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 12:55:55,950] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 12:55:55,959] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2024-09-06 12:55:55,984] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 12:55:56,263] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 12:55:56,292] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 12:55:56,303] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 12:55:56,335] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:55:56,336] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:55:56,337] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:55:56,340] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:55:56,340] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:55:56,353] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 12:55:56,354] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 12:55:56,374] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 12:55:56,395] INFO Stat of the created znode at /brokers/ids/0 is: 25,25,1725607556386,1725607556386,1,0,0,72120054421258240,202,0,25
 (kafka.zk.KafkaZkClient)
[2024-09-06 12:55:56,397] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9092, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
[2024-09-06 12:55:56,444] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:55:56,453] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:55:56,454] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:55:56,459] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2024-09-06 12:55:56,471] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 12:55:56,475] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2024-09-06 12:55:56,478] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 12:55:56,506] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 12:55:56,508] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 12:55:56,511] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 12:55:56,512] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 12:55:56,568] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:55:56,614] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:55:56,617] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:55:56,621] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:55:56,624] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 12:55:56,650] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 12:55:56,655] INFO Awaiting socket connections on localhost:9092. (kafka.network.DataPlaneAcceptor)
[2024-09-06 12:55:56,661] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 12:55:56,661] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 12:55:56,663] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 12:55:56,663] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 12:55:56,669] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 12:55:56,669] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 12:55:56,669] INFO Kafka startTimeMs: 1725607556663 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 12:55:56,674] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-09-06 12:55:56,840] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 12:55:56,856] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 12:56:20,034] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 12:56:20,287] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 12:56:20,290] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:56:20,393] INFO starting (kafka.server.KafkaServer)
[2024-09-06 12:56:20,395] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 12:56:20,408] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 12:56:20,413] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,413] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,414] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,414] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,415] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,415] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,416] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,417] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,417] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,417] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,418] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,418] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,419] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,422] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,422] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,423] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,424] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,424] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,427] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:20,468] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 12:56:20,474] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:56:20,477] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 12:56:20,479] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:56:20,482] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:52687, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:56:20,488] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10038ceb0f60001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:56:20,491] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 12:56:20,686] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 12:56:20,690] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:56:20,721] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:56:20,728] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server1-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 12:56:20,731] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:56:20,762] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:56:20,764] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:56:20,764] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:56:20,768] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:56:20,773] INFO [KafkaServer id=1] Rewriting D:\kafka\__manual-logs__\server1-logs\meta.properties (kafka.server.KafkaServer)
[2024-09-06 12:56:20,839] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 12:56:20,847] INFO No logs found to be loaded in D:\kafka\__manual-logs__\server1-logs (kafka.log.LogManager)
[2024-09-06 12:56:20,856] INFO Loaded 0 logs in 17ms (kafka.log.LogManager)
[2024-09-06 12:56:20,858] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 12:56:20,860] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 12:56:20,937] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 12:56:20,951] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 12:56:20,965] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 12:56:20,989] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 12:56:21,267] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 12:56:21,296] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 12:56:21,306] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 12:56:21,336] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:21,338] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:21,338] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:21,341] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:21,342] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:21,352] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 12:56:21,353] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 12:56:21,402] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 12:56:21,415] INFO Stat of the created znode at /brokers/ids/1 is: 45,45,1725607581409,1725607581409,1,0,0,72120054421258241,202,0,45
 (kafka.zk.KafkaZkClient)
[2024-09-06 12:56:21,415] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9093, czxid (broker epoch): 45 (kafka.zk.KafkaZkClient)
[2024-09-06 12:56:21,430] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:21,430] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:21,433] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:21,464] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:21,471] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:21,472] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:21,484] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 12:56:21,490] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 12:56:21,511] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 12:56:21,517] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 12:56:21,517] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 12:56:21,540] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:21,540] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:21,542] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:21,572] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:21,598] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 12:56:21,608] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 12:56:21,611] INFO Awaiting socket connections on localhost:9093. (kafka.network.DataPlaneAcceptor)
[2024-09-06 12:56:21,617] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 12:56:21,617] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 12:56:21,618] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 12:56:21,618] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 12:56:21,621] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 12:56:21,622] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 12:56:21,622] INFO Kafka startTimeMs: 1725607581618 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 12:56:21,624] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2024-09-06 12:56:21,746] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 12:56:21,760] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 12:56:32,579] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 12:56:32,831] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 12:56:32,834] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:56:32,935] INFO starting (kafka.server.KafkaServer)
[2024-09-06 12:56:32,936] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 12:56:32,949] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 12:56:32,955] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,955] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,956] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,959] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,959] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,959] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,960] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,961] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,961] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,961] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,962] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,962] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,963] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,963] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,963] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,964] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,964] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,965] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:32,968] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 12:56:33,011] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 12:56:33,018] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:56:33,020] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 12:56:33,021] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:56:33,024] INFO Socket connection established, initiating session, client: /127.0.0.1:52701, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:56:33,029] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10038ceb0f60002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 12:56:33,034] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 12:56:33,222] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 12:56:33,228] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:56:33,254] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:56:33,261] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server2-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 12:56:33,266] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 12:56:33,292] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:56:33,292] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:56:33,292] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:56:33,296] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 12:56:33,302] INFO [KafkaServer id=2] Rewriting D:\kafka\__manual-logs__\server2-logs\meta.properties (kafka.server.KafkaServer)
[2024-09-06 12:56:33,367] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 12:56:33,374] INFO No logs found to be loaded in D:\kafka\__manual-logs__\server2-logs (kafka.log.LogManager)
[2024-09-06 12:56:33,384] INFO Loaded 0 logs in 18ms (kafka.log.LogManager)
[2024-09-06 12:56:33,386] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 12:56:33,388] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 12:56:33,459] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 12:56:33,472] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 12:56:33,486] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 12:56:33,510] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 12:56:33,776] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 12:56:33,804] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 12:56:33,811] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 12:56:33,838] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:33,839] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:33,842] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:33,842] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:33,842] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:33,856] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 12:56:33,856] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 12:56:33,903] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 12:56:33,916] INFO Stat of the created znode at /brokers/ids/2 is: 61,61,1725607593911,1725607593911,1,0,0,72120054421258242,202,0,61
 (kafka.zk.KafkaZkClient)
[2024-09-06 12:56:33,917] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://localhost:9094, czxid (broker epoch): 61 (kafka.zk.KafkaZkClient)
[2024-09-06 12:56:33,927] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:33,927] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:33,929] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:33,962] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:33,970] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:33,970] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:33,984] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 12:56:33,989] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 12:56:34,014] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 12:56:34,018] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 12:56:34,018] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 12:56:34,044] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:34,045] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:34,047] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 12:56:34,061] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 12:56:34,087] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 12:56:34,098] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 12:56:34,101] INFO Awaiting socket connections on localhost:9094. (kafka.network.DataPlaneAcceptor)
[2024-09-06 12:56:34,105] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 12:56:34,105] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 12:56:34,106] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 12:56:34,110] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 12:56:34,112] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 12:56:34,112] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 12:56:34,112] INFO Kafka startTimeMs: 1725607594110 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 12:56:34,114] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2024-09-06 12:56:34,241] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 12:56:34,256] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:00:31,034] INFO Creating topic test-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(2), 2 -> ArrayBuffer(1), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[2024-09-06 13:00:31,154] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(test-topic-0, test-topic-3) (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:00:31,153] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test-topic-2) (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:00:31,165] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(test-topic-1, test-topic-4) (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:00:31,240] INFO [LogLoader partition=test-topic-2, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:00:31,242] INFO [LogLoader partition=test-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:00:31,253] INFO Created log for partition test-topic-2 in D:\kafka\__manual-logs__\server1-logs\test-topic-2 with properties {} (kafka.log.LogManager)
[2024-09-06 13:00:31,256] INFO [Partition test-topic-2 broker=1] No checkpointed highwatermark is found for partition test-topic-2 (kafka.cluster.Partition)
[2024-09-06 13:00:31,258] INFO [LogLoader partition=test-topic-1, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:00:31,259] INFO [Partition test-topic-2 broker=1] Log loaded for partition test-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:00:31,259] INFO Created log for partition test-topic-0 in D:\kafka\__manual-logs__\server0-logs\test-topic-0 with properties {} (kafka.log.LogManager)
[2024-09-06 13:00:31,262] INFO [Partition test-topic-0 broker=0] No checkpointed highwatermark is found for partition test-topic-0 (kafka.cluster.Partition)
[2024-09-06 13:00:31,265] INFO [Partition test-topic-0 broker=0] Log loaded for partition test-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:00:31,275] INFO Created log for partition test-topic-1 in D:\kafka\__manual-logs__\server2-logs\test-topic-1 with properties {} (kafka.log.LogManager)
[2024-09-06 13:00:31,278] INFO [Partition test-topic-1 broker=2] No checkpointed highwatermark is found for partition test-topic-1 (kafka.cluster.Partition)
[2024-09-06 13:00:31,281] INFO [Partition test-topic-1 broker=2] Log loaded for partition test-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:00:31,300] INFO [LogLoader partition=test-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:00:31,301] INFO Created log for partition test-topic-3 in D:\kafka\__manual-logs__\server0-logs\test-topic-3 with properties {} (kafka.log.LogManager)
[2024-09-06 13:00:31,305] INFO [Partition test-topic-3 broker=0] No checkpointed highwatermark is found for partition test-topic-3 (kafka.cluster.Partition)
[2024-09-06 13:00:31,305] INFO [Partition test-topic-3 broker=0] Log loaded for partition test-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:00:31,314] INFO [LogLoader partition=test-topic-4, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:00:31,315] INFO Created log for partition test-topic-4 in D:\kafka\__manual-logs__\server2-logs\test-topic-4 with properties {} (kafka.log.LogManager)
[2024-09-06 13:00:31,316] INFO [Partition test-topic-4 broker=2] No checkpointed highwatermark is found for partition test-topic-4 (kafka.cluster.Partition)
[2024-09-06 13:00:31,316] INFO [Partition test-topic-4 broker=2] Log loaded for partition test-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,014] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(2), 2 -> ArrayBuffer(1), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(2), 5 -> ArrayBuffer(1), 6 -> ArrayBuffer(0), 7 -> ArrayBuffer(2), 8 -> ArrayBuffer(1), 9 -> ArrayBuffer(0), 10 -> ArrayBuffer(2), 11 -> ArrayBuffer(1), 12 -> ArrayBuffer(0), 13 -> ArrayBuffer(2), 14 -> ArrayBuffer(1), 15 -> ArrayBuffer(0), 16 -> ArrayBuffer(2), 17 -> ArrayBuffer(1), 18 -> ArrayBuffer(0), 19 -> ArrayBuffer(2), 20 -> ArrayBuffer(1), 21 -> ArrayBuffer(0), 22 -> ArrayBuffer(2), 23 -> ArrayBuffer(1), 24 -> ArrayBuffer(0), 25 -> ArrayBuffer(2), 26 -> ArrayBuffer(1), 27 -> ArrayBuffer(0), 28 -> ArrayBuffer(2), 29 -> ArrayBuffer(1), 30 -> ArrayBuffer(0), 31 -> ArrayBuffer(2), 32 -> ArrayBuffer(1), 33 -> ArrayBuffer(0), 34 -> ArrayBuffer(2), 35 -> ArrayBuffer(1), 36 -> ArrayBuffer(0), 37 -> ArrayBuffer(2), 38 -> ArrayBuffer(1), 39 -> ArrayBuffer(0), 40 -> ArrayBuffer(2), 41 -> ArrayBuffer(1), 42 -> ArrayBuffer(0), 43 -> ArrayBuffer(2), 44 -> ArrayBuffer(1), 45 -> ArrayBuffer(0), 46 -> ArrayBuffer(2), 47 -> ArrayBuffer(1), 48 -> ArrayBuffer(0), 49 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[2024-09-06 13:01:48,101] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:01:48,102] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:01:48,103] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:01:48,121] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,122] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,122] INFO Created log for partition __consumer_offsets-35 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,122] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,123] INFO Created log for partition __consumer_offsets-3 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,124] INFO Created log for partition __consumer_offsets-37 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,125] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2024-09-06 13:01:48,126] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2024-09-06 13:01:48,126] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,126] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,128] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2024-09-06 13:01:48,128] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,159] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,160] INFO Created log for partition __consumer_offsets-5 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,160] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2024-09-06 13:01:48,161] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,161] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,162] INFO Created log for partition __consumer_offsets-18 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,165] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,163] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2024-09-06 13:01:48,167] INFO Created log for partition __consumer_offsets-7 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,167] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2024-09-06 13:01:48,167] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,167] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,186] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,187] INFO Created log for partition __consumer_offsets-20 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,188] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2024-09-06 13:01:48,188] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,191] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,193] INFO Created log for partition __consumer_offsets-39 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,194] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,196] INFO Created log for partition __consumer_offsets-22 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,196] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2024-09-06 13:01:48,196] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,194] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2024-09-06 13:01:48,197] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,213] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,215] INFO Created log for partition __consumer_offsets-41 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,215] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2024-09-06 13:01:48,215] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,221] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,222] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,223] INFO Created log for partition __consumer_offsets-10 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,223] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2024-09-06 13:01:48,224] INFO Created log for partition __consumer_offsets-9 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,224] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,224] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2024-09-06 13:01:48,226] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,242] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,243] INFO Created log for partition __consumer_offsets-29 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,243] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2024-09-06 13:01:48,244] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,251] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,251] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,252] INFO Created log for partition __consumer_offsets-24 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,253] INFO Created log for partition __consumer_offsets-31 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,253] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2024-09-06 13:01:48,253] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,252] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2024-09-06 13:01:48,255] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,265] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,266] INFO Created log for partition __consumer_offsets-44 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,266] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2024-09-06 13:01:48,266] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,278] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,279] INFO Created log for partition __consumer_offsets-46 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,279] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2024-09-06 13:01:48,280] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,282] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,283] INFO Created log for partition __consumer_offsets-27 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,285] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2024-09-06 13:01:48,285] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,297] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,298] INFO Created log for partition __consumer_offsets-14 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,298] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2024-09-06 13:01:48,298] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,306] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,307] INFO Created log for partition __consumer_offsets-1 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,307] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2024-09-06 13:01:48,307] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,310] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,311] INFO Created log for partition __consumer_offsets-42 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,312] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2024-09-06 13:01:48,312] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,317] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,318] INFO Created log for partition __consumer_offsets-2 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,319] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2024-09-06 13:01:48,319] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,328] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,329] INFO Created log for partition __consumer_offsets-16 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,330] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2024-09-06 13:01:48,330] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,335] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,336] INFO Created log for partition __consumer_offsets-12 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,337] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2024-09-06 13:01:48,340] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,340] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,341] INFO Created log for partition __consumer_offsets-23 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,341] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2024-09-06 13:01:48,341] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,351] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,353] INFO Created log for partition __consumer_offsets-19 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,353] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2024-09-06 13:01:48,353] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,361] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,361] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,361] INFO Created log for partition __consumer_offsets-38 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,361] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2024-09-06 13:01:48,361] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,361] INFO Created log for partition __consumer_offsets-33 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,362] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2024-09-06 13:01:48,363] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,375] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,375] INFO Created log for partition __consumer_offsets-34 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,376] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2024-09-06 13:01:48,376] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,384] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,384] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,385] INFO Created log for partition __consumer_offsets-8 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,385] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2024-09-06 13:01:48,385] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,385] INFO Created log for partition __consumer_offsets-48 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,387] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2024-09-06 13:01:48,390] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,398] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,398] INFO Created log for partition __consumer_offsets-4 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,399] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2024-09-06 13:01:48,400] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,406] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,407] INFO Created log for partition __consumer_offsets-11 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,407] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2024-09-06 13:01:48,407] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,412] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,413] INFO Created log for partition __consumer_offsets-21 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,414] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2024-09-06 13:01:48,414] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,421] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,422] INFO Created log for partition __consumer_offsets-25 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,422] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2024-09-06 13:01:48,422] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,429] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,430] INFO Created log for partition __consumer_offsets-26 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,431] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2024-09-06 13:01:48,431] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,438] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,440] INFO Created log for partition __consumer_offsets-36 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,440] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2024-09-06 13:01:48,442] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,445] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,446] INFO Created log for partition __consumer_offsets-40 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,446] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2024-09-06 13:01:48,447] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,454] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,455] INFO Created log for partition __consumer_offsets-47 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,455] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2024-09-06 13:01:48,455] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,467] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,468] INFO Created log for partition __consumer_offsets-6 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,469] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2024-09-06 13:01:48,470] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,471] INFO Created log for partition __consumer_offsets-43 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,471] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2024-09-06 13:01:48,472] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,470] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,478] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,479] INFO Created log for partition __consumer_offsets-17 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,480] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2024-09-06 13:01:48,480] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,494] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,494] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,494] INFO Created log for partition __consumer_offsets-45 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,494] INFO Created log for partition __consumer_offsets-13 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,495] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2024-09-06 13:01:48,494] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2024-09-06 13:01:48,495] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,495] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,500] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,501] INFO Created log for partition __consumer_offsets-32 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,501] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2024-09-06 13:01:48,501] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,506] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,507] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,508] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,509] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,509] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,509] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,509] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,509] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,509] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,509] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,510] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,510] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,510] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,510] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,510] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,510] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,510] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,511] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,511] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,511] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,511] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,511] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,511] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,511] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,511] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,512] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,512] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,512] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,512] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,512] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,512] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,513] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,513] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 5 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,513] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,514] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,514] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,514] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 5 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 5 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,516] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,516] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,517] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 5 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,517] INFO Created log for partition __consumer_offsets-28 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,517] INFO Created log for partition __consumer_offsets-15 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,518] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,518] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2024-09-06 13:01:48,519] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,519] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,518] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2024-09-06 13:01:48,521] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,539] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,539] INFO Created log for partition __consumer_offsets-49 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,540] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2024-09-06 13:01:48,541] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,541] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,542] INFO Created log for partition __consumer_offsets-30 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,544] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2024-09-06 13:01:48,544] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,548] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,549] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,551] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,552] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,552] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,553] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,553] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,553] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,553] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,553] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,553] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,554] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,554] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,554] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,554] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,554] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,555] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,555] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,555] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,555] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,555] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,556] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,556] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,556] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,556] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,556] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,557] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,557] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,557] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 6 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,557] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,558] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,558] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,558] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,559] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,559] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,559] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,559] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,559] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,559] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,560] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,560] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,560] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,561] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,561] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,561] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,562] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 6 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,562] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,562] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,562] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,563] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,563] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:01:48,563] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,563] INFO Created log for partition __consumer_offsets-0 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 13:01:48,564] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,565] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:01:48,569] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,570] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,571] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,573] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,573] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,573] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,574] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,574] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,575] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,575] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,576] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,576] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,576] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,577] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,577] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 5 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,577] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,578] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,578] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,579] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 5 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,579] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,580] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,580] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,580] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,580] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,581] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,581] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,582] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,582] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,585] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,585] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,586] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,587] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,587] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,587] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,587] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,588] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,588] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,588] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,590] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,590] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,590] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,591] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,591] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,591] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,592] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,593] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,592] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,593] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,594] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,595] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:01:48,882] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group console-consumer-35147 in Empty state. Created a new member id console-consumer-95e2877d-8e16-476a-a99e-cdeb0f5d86dd and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,902] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-35147 in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member console-consumer-95e2877d-8e16-476a-a99e-cdeb0f5d86dd with group instance id None; client reason: need to re-join with the given member-id: console-consumer-95e2877d-8e16-476a-a99e-cdeb0f5d86dd) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,911] INFO [GroupCoordinator 2]: Stabilized group console-consumer-35147 generation 1 (__consumer_offsets-1) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:01:48,936] INFO [GroupCoordinator 2]: Assignment received from leader console-consumer-95e2877d-8e16-476a-a99e-cdeb0f5d86dd for group console-consumer-35147 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:04:22,195] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-35147 in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member console-consumer-95e2877d-8e16-476a-a99e-cdeb0f5d86dd on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:04:22,196] INFO [GroupCoordinator 2]: Group console-consumer-35147 with generation 2 is now empty (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:04:22,198] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=console-consumer-95e2877d-8e16-476a-a99e-cdeb0f5d86dd, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-35147 through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:06:33,999] INFO [GroupMetadataManager brokerId=2] Group console-consumer-35147 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:06:50,943] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group console-consumer-57522 in Empty state. Created a new member id console-consumer-93bb970e-7b5b-4f06-b676-3fbe2aefdfa6 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:06:50,954] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-57522 in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member console-consumer-93bb970e-7b5b-4f06-b676-3fbe2aefdfa6 with group instance id None; client reason: need to re-join with the given member-id: console-consumer-93bb970e-7b5b-4f06-b676-3fbe2aefdfa6) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:06:50,961] INFO [GroupCoordinator 1]: Stabilized group console-consumer-57522 generation 1 (__consumer_offsets-2) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:06:50,979] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-93bb970e-7b5b-4f06-b676-3fbe2aefdfa6 for group console-consumer-57522 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:09:58,779] INFO Creating topic multi-broker-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(2), 3 -> ArrayBuffer(1), 4 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2024-09-06 13:09:58,800] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(multi-broker-topic-1, multi-broker-topic-4) (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:09:58,800] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(multi-broker-topic-0, multi-broker-topic-3) (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:09:58,800] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(multi-broker-topic-2) (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:09:58,818] INFO [LogLoader partition=multi-broker-topic-0, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:09:58,818] INFO [LogLoader partition=multi-broker-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:09:58,819] INFO [LogLoader partition=multi-broker-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:09:58,819] INFO Created log for partition multi-broker-topic-0 in D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-0 with properties {} (kafka.log.LogManager)
[2024-09-06 13:09:58,820] INFO Created log for partition multi-broker-topic-2 in D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-2 with properties {} (kafka.log.LogManager)
[2024-09-06 13:09:58,819] INFO Created log for partition multi-broker-topic-1 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-1 with properties {} (kafka.log.LogManager)
[2024-09-06 13:09:58,821] INFO [Partition multi-broker-topic-0 broker=1] No checkpointed highwatermark is found for partition multi-broker-topic-0 (kafka.cluster.Partition)
[2024-09-06 13:09:58,821] INFO [Partition multi-broker-topic-0 broker=1] Log loaded for partition multi-broker-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:09:58,822] INFO [Partition multi-broker-topic-2 broker=2] No checkpointed highwatermark is found for partition multi-broker-topic-2 (kafka.cluster.Partition)
[2024-09-06 13:09:58,822] INFO [Partition multi-broker-topic-2 broker=2] Log loaded for partition multi-broker-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:09:58,824] INFO [Partition multi-broker-topic-1 broker=0] No checkpointed highwatermark is found for partition multi-broker-topic-1 (kafka.cluster.Partition)
[2024-09-06 13:09:58,824] INFO [Partition multi-broker-topic-1 broker=0] Log loaded for partition multi-broker-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:09:58,839] INFO [LogLoader partition=multi-broker-topic-3, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:09:58,839] INFO Created log for partition multi-broker-topic-3 in D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-3 with properties {} (kafka.log.LogManager)
[2024-09-06 13:09:58,840] INFO [Partition multi-broker-topic-3 broker=1] No checkpointed highwatermark is found for partition multi-broker-topic-3 (kafka.cluster.Partition)
[2024-09-06 13:09:58,840] INFO [Partition multi-broker-topic-3 broker=1] Log loaded for partition multi-broker-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:09:58,843] INFO [LogLoader partition=multi-broker-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:09:58,843] INFO Created log for partition multi-broker-topic-4 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-4 with properties {} (kafka.log.LogManager)
[2024-09-06 13:09:58,844] INFO [Partition multi-broker-topic-4 broker=0] No checkpointed highwatermark is found for partition multi-broker-topic-4 (kafka.cluster.Partition)
[2024-09-06 13:09:58,844] INFO [Partition multi-broker-topic-4 broker=0] Log loaded for partition multi-broker-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:11:13,684] INFO [NodeToControllerChannelManager id=0 name=forwarding] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:11:17,076] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-57522 in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Removing member console-consumer-93bb970e-7b5b-4f06-b676-3fbe2aefdfa6 on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:11:17,077] INFO [GroupCoordinator 1]: Group console-consumer-57522 with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:11:17,079] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=console-consumer-93bb970e-7b5b-4f06-b676-3fbe2aefdfa6, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-57522 through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:11:36,535] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group console-consumer-59837 in Empty state. Created a new member id console-consumer-a8609044-8a0e-4e35-90dd-fda975231b7c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:11:36,545] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-59837 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member console-consumer-a8609044-8a0e-4e35-90dd-fda975231b7c with group instance id None; client reason: need to re-join with the given member-id: console-consumer-a8609044-8a0e-4e35-90dd-fda975231b7c) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:11:36,554] INFO [GroupCoordinator 0]: Stabilized group console-consumer-59837 generation 1 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:11:36,574] INFO [GroupCoordinator 0]: Assignment received from leader console-consumer-a8609044-8a0e-4e35-90dd-fda975231b7c for group console-consumer-59837 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:14:00,697] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-09-06 13:14:00,698] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2024-09-06 13:14:00,712] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 8ms (kafka.server.KafkaServer)
[2024-09-06 13:14:00,715] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 13:14:00,716] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 13:14:00,716] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 13:14:00,716] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-09-06 13:14:00,722] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-09-06 13:14:00,723] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 13:14:00,725] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 13:14:00,726] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,726] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,726] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,728] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2024-09-06 13:14:00,730] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,730] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,730] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,732] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 13:14:00,733] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2024-09-06 13:14:00,733] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 13:14:00,733] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 13:14:00,733] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 13:14:00,735] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 13:14:00,735] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:14:00,735] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,736] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,736] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,737] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,737] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,737] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,738] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:14:00,739] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-09-06 13:14:00,739] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 13:14:00,739] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 13:14:00,739] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 13:14:00,740] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:14:00,741] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:14:00,741] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 13:14:00,741] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 13:14:00,742] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,742] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,742] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,746] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,746] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,746] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,748] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,748] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,748] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,748] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,749] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,749] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,749] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,750] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,750] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:14:00,756] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 13:14:00,756] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 13:14:00,756] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 13:14:00,757] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-09-06 13:14:00,757] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:14:00,757] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:14:00,757] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:14:00,759] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 13:14:00,762] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:14:00,762] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:14:00,762] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:14:00,764] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 13:14:00,765] INFO Shutting down. (kafka.log.LogManager)
[2024-09-06 13:14:00,767] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 13:14:00,767] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 13:14:00,767] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 13:14:00,776] INFO [ProducerStateManager partition=test-topic-3] Wrote producer snapshot at offset 15 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 13:14:01,075] INFO [ProducerStateManager partition=__consumer_offsets-3] Wrote producer snapshot at offset 1 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 13:14:01,340] INFO Shutdown complete. (kafka.log.LogManager)
[2024-09-06 13:14:01,349] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 13:14:01,349] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 13:14:01,349] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 13:14:01,350] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 13:14:01,466] INFO Session: 0x10038ceb0f60000 closed (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:14:01,466] INFO EventThread shut down for session: 0x10038ceb0f60000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 13:14:01,467] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 13:14:01,472] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,474] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,474] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,475] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,475] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,475] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,477] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,477] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,477] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,478] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,479] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,479] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:14:01,482] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-09-06 13:14:01,498] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-09-06 13:14:01,499] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 13:14:01,499] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 13:14:01,503] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 13:14:01,505] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-09-06 13:14:01,506] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 13:14:01,506] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-09-06 13:14:53,422] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group console-consumer-18641 in Empty state. Created a new member id console-consumer-f5ecfca5-7f85-4ba2-8512-718a3f008e54 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:14:53,424] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-18641 in state PreparingRebalance with old generation 0 (__consumer_offsets-31) (reason: Adding new member console-consumer-f5ecfca5-7f85-4ba2-8512-718a3f008e54 with group instance id None; client reason: need to re-join with the given member-id: console-consumer-f5ecfca5-7f85-4ba2-8512-718a3f008e54) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:14:53,424] INFO [GroupCoordinator 2]: Stabilized group console-consumer-18641 generation 1 (__consumer_offsets-31) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:14:53,569] INFO [GroupCoordinator 2]: Assignment received from leader console-consumer-f5ecfca5-7f85-4ba2-8512-718a3f008e54 for group console-consumer-18641 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:16:21,509] INFO [GroupMetadataManager brokerId=1] Group console-consumer-57522 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:16:58,706] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2024-09-06 13:16:58,707] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2024-09-06 13:16:58,730] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 10ms (kafka.server.KafkaServer)
[2024-09-06 13:16:58,733] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 13:16:58,734] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 13:16:58,734] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 13:16:58,736] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2024-09-06 13:16:58,742] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2024-09-06 13:16:58,743] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 13:16:58,745] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 13:16:58,747] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,748] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,748] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,749] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2024-09-06 13:16:58,750] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,750] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,750] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,753] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 13:16:58,753] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2024-09-06 13:16:58,753] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 13:16:58,754] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 13:16:58,754] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 13:16:58,755] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 13:16:58,756] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:16:58,759] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,760] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,760] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,762] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,762] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,762] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,763] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:16:58,764] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2024-09-06 13:16:58,764] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 13:16:58,764] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 13:16:58,764] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 13:16:58,765] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:16:58,767] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:16:58,767] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 13:16:58,769] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 13:16:58,769] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,769] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,769] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,771] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,774] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,774] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,775] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,775] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,775] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,776] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,777] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,777] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,777] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,778] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,778] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:16:58,784] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 13:16:58,784] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 13:16:58,784] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 13:16:58,786] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2024-09-06 13:16:58,786] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:16:58,786] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:16:58,786] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:16:58,792] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 13:16:58,792] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:16:58,792] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:16:58,792] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:16:58,793] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 13:16:58,794] INFO Shutting down. (kafka.log.LogManager)
[2024-09-06 13:16:58,797] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 13:16:58,797] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 13:16:58,797] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 13:16:58,963] INFO [ProducerStateManager partition=multi-broker-topic-2] Wrote producer snapshot at offset 19 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 13:16:59,178] INFO [ProducerStateManager partition=__consumer_offsets-31] Wrote producer snapshot at offset 1 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 13:16:59,209] INFO [ProducerStateManager partition=__consumer_offsets-1] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 13:16:59,342] INFO Shutdown complete. (kafka.log.LogManager)
[2024-09-06 13:16:59,346] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 13:16:59,346] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 13:16:59,346] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 13:16:59,348] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 13:16:59,453] INFO Session: 0x10038ceb0f60002 closed (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:16:59,453] INFO EventThread shut down for session: 0x10038ceb0f60002 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 13:16:59,455] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 13:16:59,458] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,461] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,461] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,462] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,463] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,463] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,464] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,464] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,464] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,465] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,466] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,466] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:16:59,467] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2024-09-06 13:16:59,478] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2024-09-06 13:16:59,480] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 13:16:59,480] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 13:16:59,481] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 13:16:59,483] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-09-06 13:16:59,483] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 13:16:59,484] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2024-09-06 13:19:48,102] INFO [NodeToControllerChannelManager id=1 name=forwarding] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:19:48,104] WARN [NodeToControllerChannelManager id=1 name=forwarding] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:19:48,104] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:20:47,916] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group console-consumer-36739 in Empty state. Created a new member id console-consumer-98820c5e-2b77-4153-9e10-4ab4f57e087e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:20:47,917] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-36739 in state PreparingRebalance with old generation 0 (__consumer_offsets-29) (reason: Adding new member console-consumer-98820c5e-2b77-4153-9e10-4ab4f57e087e with group instance id None; client reason: need to re-join with the given member-id: console-consumer-98820c5e-2b77-4153-9e10-4ab4f57e087e) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:20:47,917] INFO [GroupCoordinator 1]: Stabilized group console-consumer-36739 generation 1 (__consumer_offsets-29) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:20:48,030] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-98820c5e-2b77-4153-9e10-4ab4f57e087e for group console-consumer-36739 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:21:54,341] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-36739 in state PreparingRebalance with old generation 1 (__consumer_offsets-29) (reason: Removing member console-consumer-98820c5e-2b77-4153-9e10-4ab4f57e087e on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:21:54,342] INFO [GroupCoordinator 1]: Group console-consumer-36739 with generation 2 is now empty (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:21:54,343] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=console-consumer-98820c5e-2b77-4153-9e10-4ab4f57e087e, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-36739 through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:36,414] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 13:22:36,663] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 13:22:36,666] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 13:22:36,775] INFO starting (kafka.server.KafkaServer)
[2024-09-06 13:22:36,776] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 13:22:36,790] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 13:22:36,795] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,795] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,795] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,796] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,797] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,797] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,798] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,799] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,799] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,800] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,800] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,800] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,801] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,801] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,801] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,802] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,802] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,803] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,805] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:36,845] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 13:22:36,852] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 13:22:36,854] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 13:22:36,855] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 13:22:36,859] INFO Socket connection established, initiating session, client: /127.0.0.1:53255, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 13:22:36,864] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10038ceb0f60003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 13:22:36,867] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 13:22:37,054] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 13:22:37,061] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 13:22:37,088] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 13:22:37,094] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server0-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 13:22:37,097] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 13:22:37,127] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:22:37,127] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:22:37,130] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:22:37,133] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:22:37,185] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,200] INFO Skipping recovery of 21 logs from D:\kafka\__manual-logs__\server0-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-09-06 13:22:37,278] INFO [LogLoader partition=multi-broker-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,295] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-1, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 89ms (1/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,307] INFO [LogLoader partition=multi-broker-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,309] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-4, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (2/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,324] INFO [LogLoader partition=test-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,326] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\test-topic-0, topicId=REe8ARNrTE2yDJNN0Y2ywA, topic=test-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (3/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,347] INFO [LogLoader partition=test-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,348] INFO [LogLoader partition=test-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 15 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,350] INFO [ProducerStateManager partition=test-topic-3] Loading producer state from snapshot file 'SnapshotFile(offset=15, file=D:\kafka\__manual-logs__\server0-logs\test-topic-3\00000000000000000015.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 13:22:37,365] INFO [LogLoader partition=test-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 15ms for snapshot load and 0ms for segment recovery from offset 15 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,368] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\test-topic-3, topicId=REe8ARNrTE2yDJNN0Y2ywA, topic=test-topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=15) with 1 segments, local-log-start-offset 0 and log-end-offset 15 in 42ms (4/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,384] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,387] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-0, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 18ms (5/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,398] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,400] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-12, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (6/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,410] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,412] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-15, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (7/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,422] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,425] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-18, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (8/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,435] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,438] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-21, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (9/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,447] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,449] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-24, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (10/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,461] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,463] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-27, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (11/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,478] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,478] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,479] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'SnapshotFile(offset=1, file=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-3\00000000000000000001.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 13:22:37,485] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,487] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-3, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments, local-log-start-offset 0 and log-end-offset 1 in 24ms (12/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,501] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,505] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-30, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (13/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,515] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,517] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-33, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (14/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,527] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,529] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-36, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (15/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,539] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,541] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-39, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (16/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,551] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,554] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-42, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (17/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,563] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,565] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-45, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (18/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,575] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,577] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-48, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (19/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,586] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,588] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-6, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (20/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,597] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:37,599] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-9, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (21/21 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 13:22:37,603] INFO Loaded 21 logs in 417ms (kafka.log.LogManager)
[2024-09-06 13:22:37,605] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 13:22:37,606] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 13:22:37,673] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 13:22:37,689] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 13:22:37,702] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 13:22:37,732] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:22:38,013] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 13:22:38,037] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 13:22:38,043] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:22:38,075] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:38,077] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:38,077] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:38,080] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:38,080] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:38,092] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 13:22:38,092] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 13:22:38,150] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 13:22:38,164] INFO Stat of the created znode at /brokers/ids/0 is: 257,257,1725609158160,1725609158160,1,0,0,72120054421258243,202,0,257
 (kafka.zk.KafkaZkClient)
[2024-09-06 13:22:38,165] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9092, czxid (broker epoch): 257 (kafka.zk.KafkaZkClient)
[2024-09-06 13:22:38,175] INFO [Controller id=1, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:38,176] WARN [Controller id=1, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:38,179] INFO [Controller id=1, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:38,233] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:38,243] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:38,244] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:38,260] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,271] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,291] INFO [Controller id=1, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:38,291] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 13:22:38,296] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 13:22:38,291] WARN [Controller id=1, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:38,298] INFO [Controller id=1, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:38,298] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 13:22:38,346] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:38,385] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 13:22:38,401] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 13:22:38,404] INFO Awaiting socket connections on localhost:9092. (kafka.network.DataPlaneAcceptor)
[2024-09-06 13:22:38,407] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 13:22:38,408] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 13:22:38,408] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 13:22:38,408] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 13:22:38,409] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 13:22:38,410] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 13:22:38,410] INFO Kafka startTimeMs: 1725609158408 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 13:22:38,412] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-09-06 13:22:38,474] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:22:38,489] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:22:38,507] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 1 (kafka.cluster.Partition)
[2024-09-06 13:22:38,508] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,508] INFO [Partition multi-broker-topic-1 broker=0] Log loaded for partition multi-broker-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,511] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,511] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,511] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,512] INFO [Partition test-topic-3 broker=0] Log loaded for partition test-topic-3 with initial high watermark 15 (kafka.cluster.Partition)
[2024-09-06 13:22:38,512] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,513] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,513] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,514] INFO [Partition multi-broker-topic-4 broker=0] Log loaded for partition multi-broker-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,514] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,514] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,515] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,515] INFO [Partition test-topic-0 broker=0] Log loaded for partition test-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,516] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,516] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,517] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,517] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,517] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,518] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:38,536] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-6, test-topic-0, __consumer_offsets-0, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, test-topic-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, multi-broker-topic-4, __consumer_offsets-48, __consumer_offsets-39, __consumer_offsets-12, multi-broker-topic-1, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:22:38,614] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,615] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,616] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,617] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,619] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,619] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,619] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,620] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,620] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,621] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,624] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,624] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,624] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,625] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,625] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,626] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,629] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,629] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,631] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,631] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,631] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,631] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,632] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,632] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,632] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,633] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,633] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,633] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,634] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,634] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,635] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,635] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,635] INFO Loaded member MemberMetadata(memberId=console-consumer-a8609044-8a0e-4e35-90dd-fda975231b7c, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-59837 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 13:22:38,635] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,636] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,643] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-59837 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:38,648] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 33 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,649] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 30 milliseconds for epoch 2, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,649] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 30 milliseconds for epoch 2, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,650] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 30 milliseconds for epoch 2, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,650] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 26 milliseconds for epoch 2, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,651] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 27 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,651] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 26 milliseconds for epoch 2, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,651] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 22 milliseconds for epoch 2, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,652] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 21 milliseconds for epoch 2, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,652] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 21 milliseconds for epoch 2, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,653] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 21 milliseconds for epoch 2, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,653] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 21 milliseconds for epoch 2, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,654] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 21 milliseconds for epoch 2, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,654] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 20 milliseconds for epoch 2, of which 20 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,656] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 21 milliseconds for epoch 2, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,656] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 21 milliseconds for epoch 2, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:38,659] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 22 milliseconds for epoch 2, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:55,457] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 13:22:55,692] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 13:22:55,694] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 13:22:55,784] INFO starting (kafka.server.KafkaServer)
[2024-09-06 13:22:55,784] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 13:22:55,797] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 13:22:55,802] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,803] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,803] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,804] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,804] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,805] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,807] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,807] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,810] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,810] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,810] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,811] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,811] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,811] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,812] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,812] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,813] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,814] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,816] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 13:22:55,858] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 13:22:55,866] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 13:22:55,867] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 13:22:55,869] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 13:22:55,872] INFO Socket connection established, initiating session, client: /127.0.0.1:53261, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 13:22:55,877] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10038ceb0f60004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 13:22:55,880] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 13:22:56,057] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 13:22:56,063] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 13:22:56,090] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 13:22:56,096] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server2-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 13:22:56,100] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 13:22:56,125] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:22:56,126] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:22:56,127] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:22:56,129] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 13:22:56,182] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,196] INFO Skipping recovery of 20 logs from D:\kafka\__manual-logs__\server2-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-09-06 13:22:56,268] INFO [LogLoader partition=multi-broker-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 19 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,269] INFO [LogLoader partition=multi-broker-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Reloading from producer snapshot and rebuilding producer state from offset 19 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,270] INFO [ProducerStateManager partition=multi-broker-topic-2] Loading producer state from snapshot file 'SnapshotFile(offset=19, file=D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-2\00000000000000000019.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 13:22:56,283] INFO [LogLoader partition=multi-broker-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Producer state recovery took 13ms for snapshot load and 0ms for segment recovery from offset 19 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,298] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-2, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=19) with 1 segments, local-log-start-offset 0 and log-end-offset 19 in 96ms (1/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,318] INFO [LogLoader partition=test-topic-1, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,321] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\test-topic-1, topicId=REe8ARNrTE2yDJNN0Y2ywA, topic=test-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 23ms (2/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,330] INFO [LogLoader partition=test-topic-4, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,334] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\test-topic-4, topicId=REe8ARNrTE2yDJNN0Y2ywA, topic=test-topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (3/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,348] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,348] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\kafka\__manual-logs__\server2-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,349] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-1\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 13:22:56,354] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\kafka\__manual-logs__\server2-logs] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,356] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-1, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 22ms (4/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,368] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,370] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-10, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (5/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,380] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,383] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-13, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (6/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,392] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,395] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-16, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (7/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,404] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,406] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-19, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (8/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,415] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,417] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-22, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (9/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,427] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,430] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-25, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (10/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,440] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,442] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-28, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (11/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,457] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,457] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\kafka\__manual-logs__\server2-logs] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,458] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'SnapshotFile(offset=1, file=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-31\00000000000000000001.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 13:22:56,463] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\kafka\__manual-logs__\server2-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,466] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-31, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments, local-log-start-offset 0 and log-end-offset 1 in 24ms (12/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,480] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,483] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-34, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (13/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,492] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,494] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-37, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (14/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,504] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,507] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-4, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (15/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,518] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,520] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-40, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (16/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,529] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,532] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-43, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (17/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,541] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,543] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-46, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (18/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,553] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,555] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-49, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (19/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,564] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 13:22:56,566] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-7, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (20/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 13:22:56,569] INFO Loaded 20 logs in 387ms (kafka.log.LogManager)
[2024-09-06 13:22:56,572] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 13:22:56,572] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 13:22:56,639] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 13:22:56,652] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 13:22:56,663] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 13:22:56,688] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:22:56,916] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 13:22:56,940] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 13:22:56,947] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:22:56,971] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:56,971] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:56,972] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:56,972] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:56,973] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:56,984] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 13:22:56,985] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 13:22:57,035] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 13:22:57,050] INFO Stat of the created znode at /brokers/ids/2 is: 294,294,1725609177045,1725609177045,1,0,0,72120054421258244,202,0,294
 (kafka.zk.KafkaZkClient)
[2024-09-06 13:22:57,057] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://localhost:9094, czxid (broker epoch): 294 (kafka.zk.KafkaZkClient)
[2024-09-06 13:22:57,062] INFO [Controller id=1, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:57,063] WARN [Controller id=1, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:57,068] INFO [Controller id=1, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:57,115] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:57,127] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:57,128] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:57,146] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,157] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,178] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 13:22:57,179] INFO [Controller id=1, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:57,180] WARN [Controller id=1, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:57,184] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 13:22:57,188] INFO [Controller id=1, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:22:57,189] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 13:22:57,229] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 13:22:57,265] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 13:22:57,280] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 13:22:57,283] INFO Awaiting socket connections on localhost:9094. (kafka.network.DataPlaneAcceptor)
[2024-09-06 13:22:57,286] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 13:22:57,286] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 13:22:57,287] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 13:22:57,291] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 13:22:57,292] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 13:22:57,292] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 13:22:57,293] INFO Kafka startTimeMs: 1725609177291 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 13:22:57,294] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2024-09-06 13:22:57,378] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:22:57,390] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,391] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,391] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,392] INFO [Partition test-topic-1 broker=2] Log loaded for partition test-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,393] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,395] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 1 (kafka.cluster.Partition)
[2024-09-06 13:22:57,395] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,399] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 3 (kafka.cluster.Partition)
[2024-09-06 13:22:57,399] INFO [Partition multi-broker-topic-2 broker=2] Log loaded for partition multi-broker-topic-2 with initial high watermark 19 (kafka.cluster.Partition)
[2024-09-06 13:22:57,400] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,400] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,401] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,401] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,402] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,402] INFO [Partition test-topic-4 broker=2] Log loaded for partition test-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,403] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,404] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,404] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,404] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,405] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 13:22:57,426] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, multi-broker-topic-2, test-topic-1, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, test-topic-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2024-09-06 13:22:57,440] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 13:22:57,512] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,512] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,514] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,516] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,516] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,517] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,517] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,518] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,518] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 4 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,518] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,519] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 3 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,519] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,520] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 3 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,520] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,521] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 2 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,521] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,521] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,522] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,522] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,522] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,523] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,523] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,523] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,524] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,524] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,525] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,525] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,525] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,526] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,526] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,526] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,527] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,527] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,527] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,528] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,528] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,528] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,529] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,536] INFO Loaded member MemberMetadata(memberId=console-consumer-f5ecfca5-7f85-4ba2-8512-718a3f008e54, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-18641 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 13:22:57,540] INFO [GroupCoordinator 2]: Loading group metadata for console-consumer-18641 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:22:57,544] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 24 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,544] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 23 milliseconds for epoch 2, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,547] INFO Loaded member MemberMetadata(memberId=console-consumer-95e2877d-8e16-476a-a99e-cdeb0f5d86dd, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-35147 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 13:22:57,547] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 25 milliseconds for epoch 2, of which 23 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,548] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 25 milliseconds for epoch 2, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,548] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 25 milliseconds for epoch 2, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,548] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 24 milliseconds for epoch 2, of which 24 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,551] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 26 milliseconds for epoch 2, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,551] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 26 milliseconds for epoch 2, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,553] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 27 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,553] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 26 milliseconds for epoch 2, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,553] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 25 milliseconds for epoch 2, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,553] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 25 milliseconds for epoch 2, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:22:57,554] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 25 milliseconds for epoch 2, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:23:23,657] INFO [GroupCoordinator 0]: Member console-consumer-a8609044-8a0e-4e35-90dd-fda975231b7c in group console-consumer-59837 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:23:23,663] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-59837 in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: removing member console-consumer-a8609044-8a0e-4e35-90dd-fda975231b7c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:23:23,664] INFO [GroupCoordinator 0]: Group console-consumer-59837 with generation 2 is now empty (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:23:42,560] INFO [GroupCoordinator 2]: Member console-consumer-f5ecfca5-7f85-4ba2-8512-718a3f008e54 in group console-consumer-18641 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:23:42,564] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-18641 in state PreparingRebalance with old generation 1 (__consumer_offsets-31) (reason: removing member console-consumer-f5ecfca5-7f85-4ba2-8512-718a3f008e54 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:23:42,566] INFO [GroupCoordinator 2]: Group console-consumer-18641 with generation 2 is now empty (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:26:21,504] INFO [GroupMetadataManager brokerId=1] Group console-consumer-36739 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:29:48,207] INFO [NodeToControllerChannelManager id=1 name=forwarding] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 13:32:38,287] INFO [GroupMetadataManager brokerId=0] Group console-consumer-59837 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:32:57,164] INFO [GroupMetadataManager brokerId=2] Group console-consumer-18641 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 13:46:09,642] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group console-consumer-67901 in Empty state. Created a new member id console-consumer-89e59505-d0d2-41a3-8b0f-d2e2d64dab2d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:46:09,648] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-67901 in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member console-consumer-89e59505-d0d2-41a3-8b0f-d2e2d64dab2d with group instance id None; client reason: need to re-join with the given member-id: console-consumer-89e59505-d0d2-41a3-8b0f-d2e2d64dab2d) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:46:09,652] INFO [GroupCoordinator 2]: Stabilized group console-consumer-67901 generation 1 (__consumer_offsets-4) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:46:09,672] INFO [GroupCoordinator 2]: Assignment received from leader console-consumer-89e59505-d0d2-41a3-8b0f-d2e2d64dab2d for group console-consumer-67901 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 13:55:56,169] INFO [NodeToControllerChannelManager id=2 name=forwarding] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:40:16,976] INFO Creating 1 partitions for 'multi-broker-topic' with the following replica assignment: HashMap(5 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=)). (kafka.zk.AdminZkClient)
[2024-09-06 15:40:17,021] INFO [Controller id=1, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:40:17,021] INFO [Controller id=1, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:40:17,021] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:40:17,033] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(multi-broker-topic-5) (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:40:17,061] INFO [LogLoader partition=multi-broker-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:40:17,064] INFO Created log for partition multi-broker-topic-5 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-5 with properties {} (kafka.log.LogManager)
[2024-09-06 15:40:17,066] INFO [Partition multi-broker-topic-5 broker=0] No checkpointed highwatermark is found for partition multi-broker-topic-5 (kafka.cluster.Partition)
[2024-09-06 15:40:17,067] INFO [Partition multi-broker-topic-5 broker=0] Log loaded for partition multi-broker-topic-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:44:42,889] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-09-06 15:44:42,891] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2024-09-06 15:44:42,905] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 2ms (kafka.server.KafkaServer)
[2024-09-06 15:44:42,910] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:44:42,911] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:44:42,911] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:44:42,914] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-09-06 15:44:42,924] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-09-06 15:44:42,928] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 15:44:42,932] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 15:44:42,934] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,935] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,935] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,937] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2024-09-06 15:44:42,939] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,939] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,940] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,946] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:44:42,947] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2024-09-06 15:44:42,947] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:44:42,948] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:44:42,948] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:44:42,950] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:44:42,951] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:44:42,952] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,952] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,952] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,953] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,954] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,954] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,956] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:44:42,960] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-09-06 15:44:42,961] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:44:42,961] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:44:42,961] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:44:42,962] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:44:42,963] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:44:42,963] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 15:44:42,964] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 15:44:42,964] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,964] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,964] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,965] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,966] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,966] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,967] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,967] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,967] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,968] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,968] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,968] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,969] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,969] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,969] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:44:42,976] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:44:42,976] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:44:42,977] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:44:42,977] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-09-06 15:44:42,979] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:44:42,979] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:44:42,979] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:44:42,982] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 15:44:42,982] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:44:42,982] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:44:42,982] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:44:42,984] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 15:44:42,985] INFO Shutting down. (kafka.log.LogManager)
[2024-09-06 15:44:42,988] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:44:42,991] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:44:42,991] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:44:42,996] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-67901 in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Leader console-consumer-89e59505-d0d2-41a3-8b0f-d2e2d64dab2d re-joining group during Stable; client reason: cached metadata has changed) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:44:43,001] INFO [GroupCoordinator 2]: Stabilized group console-consumer-67901 generation 2 (__consumer_offsets-4) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:44:43,255] INFO [ProducerStateManager partition=multi-broker-topic-1] Wrote producer snapshot at offset 2 with 1 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:44:43,315] INFO [ProducerStateManager partition=__consumer_offsets-3] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:44:43,357] INFO [GroupCoordinator 2]: Assignment received from leader console-consumer-89e59505-d0d2-41a3-8b0f-d2e2d64dab2d for group console-consumer-67901 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:44:43,627] INFO Shutdown complete. (kafka.log.LogManager)
[2024-09-06 15:44:43,636] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:44:43,637] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:44:43,637] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:44:43,638] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:44:43,754] INFO Session: 0x10038ceb0f60003 closed (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:44:43,754] INFO EventThread shut down for session: 0x10038ceb0f60003 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:44:43,755] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:44:43,759] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,761] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,761] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,761] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,762] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,762] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,763] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,763] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,763] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,764] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,764] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,764] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:44:43,765] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-09-06 15:44:43,777] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-09-06 15:44:43,778] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 15:44:43,778] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 15:44:43,780] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 15:44:43,782] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-09-06 15:44:43,783] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:44:43,784] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-09-06 15:44:52,474] WARN Session 0x10038ceb0f60001 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:74)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:44:52,481] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:74)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:44:54,055] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:44:54,060] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:44:54,278] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:44:54,279] WARN Session 0x10038ceb0f60001 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:44:55,636] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:44:55,637] WARN Session 0x10038ceb0f60001 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:44:55,929] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:44:55,931] WARN Session 0x10038ceb0f60004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:44:57,601] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:44:57,602] WARN Session 0x10038ceb0f60001 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:44:57,950] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:44:57,951] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:44:59,582] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:44:59,583] WARN Session 0x10038ceb0f60001 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:44:59,783] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:44:59,783] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:00,728] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2024-09-06 15:45:00,732] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2024-09-06 15:45:00,745] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 2ms (kafka.server.KafkaServer)
[2024-09-06 15:45:00,749] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:45:00,749] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:45:00,749] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:45:00,754] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2024-09-06 15:45:00,764] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2024-09-06 15:45:00,766] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 15:45:00,769] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 15:45:00,773] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,774] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,774] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,780] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2024-09-06 15:45:00,782] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,783] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,783] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,786] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:45:00,788] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2024-09-06 15:45:00,788] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:45:00,789] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:45:00,789] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:45:00,793] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:45:00,794] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:45:00,795] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,795] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,795] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,796] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,797] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,797] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,798] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:45:00,799] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2024-09-06 15:45:00,800] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:45:00,801] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:45:00,801] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:45:00,805] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:45:00,806] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:45:00,807] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 15:45:00,808] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 15:45:00,808] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,809] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,809] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,811] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,812] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,812] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,816] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,817] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,817] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,819] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,820] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,820] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,821] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,822] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,822] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:00,829] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:45:00,829] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:45:00,829] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:45:00,830] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2024-09-06 15:45:00,834] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:00,834] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:00,834] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:00,837] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 15:45:00,838] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:00,838] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:00,838] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:00,839] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 15:45:00,839] INFO Shutting down. (kafka.log.LogManager)
[2024-09-06 15:45:00,842] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:45:00,842] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:45:00,842] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:45:00,859] INFO [ProducerStateManager partition=__consumer_offsets-29] Wrote producer snapshot at offset 3 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:45:00,922] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:00,923] WARN Session 0x10038ceb0f60001 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:01,019] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:01,020] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:01,158] INFO [ProducerStateManager partition=multi-broker-topic-3] Wrote producer snapshot at offset 18 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:45:01,212] INFO [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:45:01,430] INFO Shutdown complete. (kafka.log.LogManager)
[2024-09-06 15:45:01,437] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:45:01,438] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:45:01,438] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:45:01,439] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:45:02,821] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:02,822] WARN Session 0x10038ceb0f60004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:02,969] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:03,080] INFO Session: 0x10038ceb0f60001 closed (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:45:03,080] INFO EventThread shut down for session: 0x10038ceb0f60001 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:03,081] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:45:03,084] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,086] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,087] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,086] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,088] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,088] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,087] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,089] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,089] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,088] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,090] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,090] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:03,094] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2024-09-06 15:45:03,112] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2024-09-06 15:45:03,113] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 15:45:03,113] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 15:45:03,114] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 15:45:03,115] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-09-06 15:45:03,117] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:45:03,117] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2024-09-06 15:45:04,876] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:04,877] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:06,943] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:06,944] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:08,539] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:08,540] WARN Session 0x10038ceb0f60004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:10,180] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:10,181] WARN Session 0x10038ceb0f60004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:11,832] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:11,833] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:12,792] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-67901 in state PreparingRebalance with old generation 2 (__consumer_offsets-4) (reason: Removing member console-consumer-89e59505-d0d2-41a3-8b0f-d2e2d64dab2d on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:45:12,792] INFO [GroupCoordinator 2]: Group console-consumer-67901 with generation 3 is now empty (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:45:12,796] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=console-consumer-89e59505-d0d2-41a3-8b0f-d2e2d64dab2d, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-67901 through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:45:13,881] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:13,881] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:15,869] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:15,870] WARN Session 0x10038ceb0f60004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:17,573] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:17,574] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:19,645] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:19,646] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:20,937] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:20,938] WARN Session 0x10038ceb0f60004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:22,833] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:22,833] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:24,626] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:24,627] WARN Session 0x10038ceb0f60004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:26,197] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:28,125] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:28,321] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2024-09-06 15:45:28,324] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2024-09-06 15:45:28,339] INFO [KafkaServer id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:45:28,340] WARN [KafkaServer id=2] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:45:28,341] WARN [KafkaServer id=2] Error during controlled shutdown, possibly because leader movement took longer than the configured controller.socket.timeout.ms and/or request.timeout.ms: Connection to localhost:9093 (id: 1 rack: null) failed. (kafka.server.KafkaServer)
[2024-09-06 15:45:29,537] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:29,538] WARN Session 0x10038ceb0f60004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:31,064] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:31,065] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:32,393] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:32,394] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:33,357] INFO [KafkaServer id=2] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2024-09-06 15:45:33,358] INFO [KafkaServer id=2] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:45:33,360] INFO [KafkaServer id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:45:33,362] WARN [KafkaServer id=2] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:45:33,362] WARN [KafkaServer id=2] Error during controlled shutdown, possibly because leader movement took longer than the configured controller.socket.timeout.ms and/or request.timeout.ms: Connection to localhost:9093 (id: 1 rack: null) failed. (kafka.server.KafkaServer)
[2024-09-06 15:45:34,138] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:34,139] WARN Session 0x10038ceb0f60004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:35,718] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:35,719] WARN Session 0x10038ceb0f60004 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:37,098] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:38,288] WARN Session 0x10038ceb0f60004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 15:45:38,370] INFO [KafkaServer id=2] Retrying controlled shutdown (1 retries remaining) (kafka.server.KafkaServer)
[2024-09-06 15:45:38,370] INFO [KafkaServer id=2] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:45:38,371] INFO [KafkaServer id=2] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:45:38,371] WARN [KafkaServer id=2] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:45:38,372] WARN [KafkaServer id=2] Error during controlled shutdown, possibly because leader movement took longer than the configured controller.socket.timeout.ms and/or request.timeout.ms: Connection to localhost:9093 (id: 1 rack: null) failed. (kafka.server.KafkaServer)
[2024-09-06 15:45:38,377] WARN [KafkaServer id=2] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2024-09-06 15:45:38,379] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:45:38,379] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:45:38,379] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:45:38,381] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2024-09-06 15:45:38,389] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2024-09-06 15:45:38,391] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 15:45:38,393] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 15:45:38,396] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,397] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,397] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,398] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2024-09-06 15:45:38,401] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,402] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,402] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,404] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:45:38,404] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2024-09-06 15:45:38,404] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:45:38,405] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:45:38,405] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:45:38,407] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:45:38,408] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:45:38,409] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,409] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,409] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,410] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,410] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,410] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,410] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:45:38,412] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2024-09-06 15:45:38,413] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:45:38,414] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:45:38,414] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:45:38,415] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:45:38,416] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:45:38,417] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 15:45:38,417] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 15:45:38,417] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,417] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,417] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,418] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,418] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,418] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,419] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,419] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,419] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,419] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,420] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,420] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,420] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,420] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,420] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:45:38,428] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:45:38,429] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:45:38,429] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:45:38,429] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2024-09-06 15:45:38,430] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:38,430] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:38,430] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:38,432] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 15:45:38,433] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:38,433] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:38,433] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:45:38,433] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 15:45:38,434] INFO Shutting down. (kafka.log.LogManager)
[2024-09-06 15:45:38,437] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:45:38,438] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:45:38,438] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:45:38,786] INFO [ProducerStateManager partition=__consumer_offsets-4] Wrote producer snapshot at offset 3 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:45:38,811] INFO [ProducerStateManager partition=__consumer_offsets-31] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:45:39,024] INFO Shutdown complete. (kafka.log.LogManager)
[2024-09-06 15:45:39,036] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:45:39,037] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:45:39,037] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:45:39,038] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:45:39,956] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:45,848] INFO Session: 0x10038ceb0f60004 closed (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:45:45,848] INFO EventThread shut down for session: 0x10038ceb0f60004 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:45:45,849] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:45:45,849] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,851] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,851] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,851] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,851] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,851] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,851] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,851] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,851] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,852] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,852] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,852] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:45:45,852] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2024-09-06 15:45:45,868] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2024-09-06 15:45:45,869] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 15:45:45,869] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 15:45:45,869] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 15:45:45,870] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-09-06 15:45:45,873] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:45:45,874] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2024-09-06 15:46:15,177] INFO Reading configuration from: D:\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 15:46:15,184] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 15:46:15,185] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 15:46:15,185] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 15:46:15,185] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 15:46:15,186] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-09-06 15:46:15,187] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-09-06 15:46:15,187] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-09-06 15:46:15,187] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-09-06 15:46:15,188] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-09-06 15:46:15,188] INFO Reading configuration from: D:\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 15:46:15,190] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 15:46:15,190] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 15:46:15,190] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 15:46:15,190] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-09-06 15:46:15,191] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-09-06 15:46:15,202] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@659a969b (org.apache.zookeeper.server.ServerMetrics)
[2024-09-06 15:46:15,204] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-09-06 15:46:15,205] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-09-06 15:46:15,206] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-09-06 15:46:15,213] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,213] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,214] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,214] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,215] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,215] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,215] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,216] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,218] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,218] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,221] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,221] INFO Server environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,222] INFO Server environment:java.version=19.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,222] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,223] INFO Server environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,223] INFO Server environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,224] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,225] INFO Server environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,225] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,225] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,225] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,226] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,226] INFO Server environment:user.name=Jerin.sam (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,227] INFO Server environment:user.home=C:\Users\jerin (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,227] INFO Server environment:user.dir=C:\Users\jerin (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,227] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,228] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,228] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,228] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,229] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,229] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,230] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,230] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,230] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,231] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,237] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-09-06 15:46:15,238] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,238] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,239] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-09-06 15:46:15,239] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-09-06 15:46:15,240] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 15:46:15,240] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 15:46:15,240] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 15:46:15,241] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 15:46:15,241] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 15:46:15,242] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-09-06 15:46:15,245] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,245] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,245] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-09-06 15:46:15,245] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-09-06 15:46:15,246] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir D:\kafka\__manual-logs__\zookeeper-logs\version-2 snapdir D:\kafka\__manual-logs__\zookeeper-logs\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,251] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-09-06 15:46:15,253] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-09-06 15:46:15,255] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-09-06 15:46:15,294] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-09-06 15:46:15,316] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-09-06 15:46:15,316] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-09-06 15:46:15,317] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-09-06 15:46:15,317] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-09-06 15:46:15,322] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-09-06 15:46:15,326] INFO Reading snapshot D:\kafka\__manual-logs__\zookeeper-logs\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-09-06 15:46:15,330] INFO The digest value is empty in snapshot (org.apache.zookeeper.server.DataTree)
[2024-09-06 15:46:15,366] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-09-06 15:46:15,376] INFO 343 txns loaded in 38 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-09-06 15:46:15,377] INFO Snapshot loaded in 59 ms, highest zxid is 0x157, digest is 316575404750 (org.apache.zookeeper.server.ZKDatabase)
[2024-09-06 15:46:15,378] INFO Snapshotting: 0x157 to D:\kafka\__manual-logs__\zookeeper-logs\version-2\snapshot.157 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-09-06 15:46:15,381] INFO Snapshot taken in 4 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:15,391] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-09-06 15:46:15,391] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-09-06 15:46:15,416] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-09-06 15:46:23,609] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 15:46:23,888] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 15:46:23,892] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:24,028] INFO starting (kafka.server.KafkaServer)
[2024-09-06 15:46:24,029] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 15:46:24,043] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:46:24,048] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,049] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,051] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,054] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,054] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,054] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,056] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,056] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,056] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,057] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,057] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,057] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,058] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,058] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,058] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,059] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,059] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,060] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,062] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:24,111] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 15:46:24,120] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:24,122] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:46:24,123] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:24,125] INFO Socket connection established, initiating session, client: /127.0.0.1:58073, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:24,131] INFO Creating new log file: log.158 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-09-06 15:46:24,141] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100396b1a210000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:24,145] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:46:24,367] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 15:46:24,375] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:24,406] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:24,414] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server0-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 15:46:24,418] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:24,454] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:24,456] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:24,456] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:24,459] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:24,520] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,537] INFO Skipping recovery of 22 logs from D:\kafka\__manual-logs__\server0-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-09-06 15:46:24,622] INFO [LogLoader partition=multi-broker-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,623] INFO [LogLoader partition=multi-broker-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,624] INFO [ProducerStateManager partition=multi-broker-topic-1] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-1\00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:46:24,637] INFO [LogLoader partition=multi-broker-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 13ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,651] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-1, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 106ms (1/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,665] INFO [LogLoader partition=multi-broker-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,671] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-4, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (2/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,680] INFO [LogLoader partition=multi-broker-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,685] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-5, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (3/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,695] INFO [LogLoader partition=test-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,698] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\test-topic-0, topicId=REe8ARNrTE2yDJNN0Y2ywA, topic=test-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (4/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,721] INFO [LogLoader partition=test-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,721] INFO [LogLoader partition=test-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 15 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,721] INFO [ProducerStateManager partition=test-topic-3] Loading producer state from snapshot file 'SnapshotFile(offset=15, file=D:\kafka\__manual-logs__\server0-logs\test-topic-3\00000000000000000015.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:46:24,723] INFO [LogLoader partition=test-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 15 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,725] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\test-topic-3, topicId=REe8ARNrTE2yDJNN0Y2ywA, topic=test-topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=15) with 1 segments, local-log-start-offset 0 and log-end-offset 15 in 26ms (5/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,740] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,743] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-0, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 18ms (6/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,756] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,759] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-12, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (7/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,772] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,774] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-15, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 15ms (8/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,786] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,788] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-18, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (9/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,799] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,802] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-21, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (10/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,813] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,816] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-24, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (11/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,826] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,829] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-27, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (12/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,846] INFO Deleted producer state snapshot D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-3\00000000000000000001.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-09-06 15:46:24,847] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,847] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,851] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-3\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:46:24,854] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,857] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-3, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 29ms (13/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,871] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,874] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-30, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (14/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,883] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,887] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-33, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (15/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,897] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,900] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-36, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (16/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,910] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,912] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-39, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (17/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,923] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,925] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-42, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (18/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,935] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,938] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-45, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (19/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,949] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,952] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-48, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (20/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,961] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,963] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-6, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (21/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,975] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:24,977] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-9, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (22/22 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:46:24,981] INFO Loaded 22 logs in 459ms (kafka.log.LogManager)
[2024-09-06 15:46:24,984] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 15:46:24,985] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 15:46:25,061] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:46:25,078] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:46:25,099] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 15:46:25,137] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:25,454] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 15:46:25,488] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 15:46:25,497] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:25,533] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:25,534] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:25,538] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:25,538] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:25,538] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:25,552] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:46:25,552] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:46:25,617] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 15:46:25,640] INFO Stat of the created znode at /brokers/ids/0 is: 359,359,1725617785631,1725617785631,1,0,0,72120726200582144,202,0,359
 (kafka.zk.KafkaZkClient)
[2024-09-06 15:46:25,640] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9092, czxid (broker epoch): 359 (kafka.zk.KafkaZkClient)
[2024-09-06 15:46:25,695] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:25,703] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:25,704] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:25,721] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:25,734] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:25,756] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:46:25,760] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:46:25,760] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:46:25,821] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:25,861] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:46:25,887] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 15:46:25,890] INFO Awaiting socket connections on localhost:9092. (kafka.network.DataPlaneAcceptor)
[2024-09-06 15:46:25,893] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:46:25,893] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:46:25,894] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:46:25,897] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:46:25,899] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:46:25,900] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:46:25,900] INFO Kafka startTimeMs: 1725617785897 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:46:25,901] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-09-06 15:46:34,030] INFO Expiring session 0x10038ceb0f60001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:34,030] INFO Expiring session 0x10038ceb0f60004, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:46:34,145] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 15:46:34,223] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:34,254] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:34,301] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 3 (kafka.cluster.Partition)
[2024-09-06 15:46:34,303] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,304] INFO [Partition multi-broker-topic-1 broker=0] Log loaded for partition multi-broker-topic-1 with initial high watermark 2 (kafka.cluster.Partition)
[2024-09-06 15:46:34,307] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,308] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,309] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,309] INFO [Partition test-topic-3 broker=0] Log loaded for partition test-topic-3 with initial high watermark 15 (kafka.cluster.Partition)
[2024-09-06 15:46:34,310] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,311] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,312] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,313] INFO [Partition multi-broker-topic-4 broker=0] Log loaded for partition multi-broker-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,313] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,315] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,315] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,315] INFO [Partition test-topic-0 broker=0] Log loaded for partition test-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,316] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,317] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,318] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,322] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,324] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,325] INFO [Partition multi-broker-topic-5 broker=0] Log loaded for partition multi-broker-topic-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,325] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:34,384] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, test-topic-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, multi-broker-topic-4, __consumer_offsets-48, multi-broker-topic-5, test-topic-0, __consumer_offsets-39, __consumer_offsets-12, multi-broker-topic-1, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:46:34,515] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,516] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,519] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,521] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,521] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,522] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,523] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,523] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,524] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,524] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,525] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,525] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,526] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,527] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,527] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,528] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,528] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,529] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,530] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,532] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,533] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,534] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,535] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,539] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,540] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,542] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,542] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,543] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,543] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,544] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,544] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,545] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:34,545] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,555] INFO Loaded member MemberMetadata(memberId=console-consumer-a8609044-8a0e-4e35-90dd-fda975231b7c, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-59837 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 15:46:34,566] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 48 milliseconds for epoch 4, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,567] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 46 milliseconds for epoch 4, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,567] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 45 milliseconds for epoch 4, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,571] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 48 milliseconds for epoch 4, of which 48 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,572] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 47 milliseconds for epoch 4, of which 47 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,572] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 47 milliseconds for epoch 4, of which 47 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,572] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 45 milliseconds for epoch 4, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,573] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 45 milliseconds for epoch 4, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,573] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 44 milliseconds for epoch 4, of which 44 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,573] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 41 milliseconds for epoch 4, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,574] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 40 milliseconds for epoch 4, of which 40 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,575] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 36 milliseconds for epoch 4, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,575] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 34 milliseconds for epoch 4, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,576] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 33 milliseconds for epoch 4, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,577] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 33 milliseconds for epoch 4, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,577] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 32 milliseconds for epoch 4, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,578] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 32 milliseconds for epoch 4, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:34,583] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 15:46:34,587] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:34,696] INFO starting (kafka.server.KafkaServer)
[2024-09-06 15:46:34,697] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 15:46:34,712] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:46:34,717] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,717] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,718] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,722] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,722] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,723] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,724] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,725] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,725] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,726] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,726] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,727] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,727] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,727] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,728] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,728] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,728] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,729] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,734] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:34,782] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 15:46:34,789] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:34,791] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:46:34,793] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:34,798] INFO Socket connection established, initiating session, client: /127.0.0.1:58082, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:34,803] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100396b1a210001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:34,806] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:46:35,008] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 15:46:35,019] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:35,051] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:35,058] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server1-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 15:46:35,061] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:35,092] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:35,094] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:35,098] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:35,098] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:35,158] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,173] INFO Skipping recovery of 19 logs from D:\kafka\__manual-logs__\server1-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-09-06 15:46:35,252] INFO [LogLoader partition=multi-broker-topic-0, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,273] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-0, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 94ms (1/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,332] INFO [LogLoader partition=multi-broker-topic-3, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 18 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,332] INFO [LogLoader partition=multi-broker-topic-3, dir=D:\kafka\__manual-logs__\server1-logs] Reloading from producer snapshot and rebuilding producer state from offset 18 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,333] INFO [ProducerStateManager partition=multi-broker-topic-3] Loading producer state from snapshot file 'SnapshotFile(offset=18, file=D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-3\00000000000000000018.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:46:35,347] INFO [LogLoader partition=multi-broker-topic-3, dir=D:\kafka\__manual-logs__\server1-logs] Producer state recovery took 14ms for snapshot load and 0ms for segment recovery from offset 18 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,355] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-3, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=18) with 1 segments, local-log-start-offset 0 and log-end-offset 18 in 82ms (2/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,387] INFO [LogLoader partition=test-topic-2, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,396] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\test-topic-2, topicId=REe8ARNrTE2yDJNN0Y2ywA, topic=test-topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 39ms (3/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,421] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,427] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-11, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 30ms (4/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,449] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,457] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-14, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 30ms (5/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,473] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,479] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-17, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 22ms (6/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,502] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,502] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\kafka\__manual-logs__\server1-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,504] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-2\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:46:35,509] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\kafka\__manual-logs__\server1-logs] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,515] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-2, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 36ms (7/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,536] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,542] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-20, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 26ms (8/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,555] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,562] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-23, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 20ms (9/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,580] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,588] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-26, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 25ms (10/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,612] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,613] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\kafka\__manual-logs__\server1-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,617] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-29\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:46:35,623] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\kafka\__manual-logs__\server1-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,627] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-29, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 38ms (11/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,646] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,652] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-32, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 25ms (12/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,671] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,679] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-35, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 27ms (13/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,695] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,703] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-38, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 24ms (14/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,722] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,728] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-41, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 24ms (15/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,745] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,756] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-44, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 27ms (16/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,775] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,789] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-47, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 32ms (17/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,812] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,819] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-5, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 30ms (18/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,838] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:35,846] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-8, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 26ms (19/19 completed in D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:46:35,852] INFO Loaded 19 logs in 692ms (kafka.log.LogManager)
[2024-09-06 15:46:35,855] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 15:46:35,856] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 15:46:35,941] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:46:35,955] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:46:35,975] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 15:46:36,007] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:36,347] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 15:46:36,386] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 15:46:36,394] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:36,435] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:36,437] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:36,443] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:36,444] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:36,444] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:36,463] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:46:36,464] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:46:36,539] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 15:46:36,562] INFO Stat of the created znode at /brokers/ids/1 is: 440,440,1725617796555,1725617796555,1,0,0,72120726200582145,202,0,440
 (kafka.zk.KafkaZkClient)
[2024-09-06 15:46:36,565] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9093, czxid (broker epoch): 440 (kafka.zk.KafkaZkClient)
[2024-09-06 15:46:36,592] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:36,597] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:36,603] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:36,656] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:36,669] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:36,669] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:36,680] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:36,693] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:36,718] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:36,725] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:46:36,734] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:36,742] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:46:36,737] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:36,748] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:46:36,804] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:36,847] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:36,852] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:36,860] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:36,874] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:46:36,922] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 15:46:36,932] INFO Awaiting socket connections on localhost:9093. (kafka.network.DataPlaneAcceptor)
[2024-09-06 15:46:36,939] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:46:36,940] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:46:36,941] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:46:36,941] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:46:36,944] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:46:36,944] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:46:36,945] INFO Kafka startTimeMs: 1725617796942 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:46:36,948] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2024-09-06 15:46:37,060] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:37,104] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:37,105] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,107] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,110] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,111] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,111] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 3 (kafka.cluster.Partition)
[2024-09-06 15:46:37,112] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,113] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,113] INFO [Partition multi-broker-topic-0 broker=1] Log loaded for partition multi-broker-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,114] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 3 (kafka.cluster.Partition)
[2024-09-06 15:46:37,114] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,115] INFO [Partition test-topic-2 broker=1] Log loaded for partition test-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,116] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,116] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,117] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,117] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,117] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,118] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,118] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:37,119] INFO [Partition multi-broker-topic-3 broker=1] Log loaded for partition multi-broker-topic-3 with initial high watermark 18 (kafka.cluster.Partition)
[2024-09-06 15:46:37,144] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(multi-broker-topic-0, __consumer_offsets-35, test-topic-2, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, multi-broker-topic-3, __consumer_offsets-8, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:46:37,230] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,230] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,233] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,235] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,235] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,235] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,236] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,236] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,237] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,237] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,237] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,238] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,238] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 6 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,238] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,239] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 4 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,239] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,239] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 3 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,240] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,240] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,240] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,241] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,242] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,242] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,243] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,247] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,247] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,249] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,250] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,251] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,251] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,251] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,252] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,252] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,252] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,253] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:37,253] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,264] INFO Loaded member MemberMetadata(memberId=console-consumer-98820c5e-2b77-4153-9e10-4ab4f57e087e, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-36739 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 15:46:37,269] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 32 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,269] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 31 milliseconds for epoch 2, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,270] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 30 milliseconds for epoch 2, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,273] INFO Loaded member MemberMetadata(memberId=console-consumer-93bb970e-7b5b-4f06-b676-3fbe2aefdfa6, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-57522 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 15:46:37,273] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 32 milliseconds for epoch 2, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,274] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 32 milliseconds for epoch 2, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,279] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 32 milliseconds for epoch 2, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,279] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 30 milliseconds for epoch 2, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,280] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 29 milliseconds for epoch 2, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,281] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 30 milliseconds for epoch 2, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,281] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 29 milliseconds for epoch 2, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,282] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 29 milliseconds for epoch 2, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:37,282] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 29 milliseconds for epoch 2, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:39,954] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 15:46:40,239] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 15:46:40,242] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:40,363] INFO starting (kafka.server.KafkaServer)
[2024-09-06 15:46:40,363] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 15:46:40,379] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:46:40,384] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,384] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,384] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,387] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,388] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,388] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,389] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,389] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,390] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,390] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,390] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,391] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,391] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,392] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,392] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,392] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,393] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,393] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,396] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:46:40,449] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 15:46:40,458] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:40,459] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:46:40,461] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:40,466] INFO Socket connection established, initiating session, client: /127.0.0.1:58091, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:40,471] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100396b1a210002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:46:40,474] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:46:40,697] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 15:46:40,708] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:40,747] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:40,757] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server2-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 15:46:40,761] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:46:40,801] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:40,803] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:40,805] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:40,808] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:46:40,890] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:40,922] INFO Skipping recovery of 20 logs from D:\kafka\__manual-logs__\server2-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-09-06 15:46:41,036] INFO [LogLoader partition=multi-broker-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 19 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,037] INFO [LogLoader partition=multi-broker-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Reloading from producer snapshot and rebuilding producer state from offset 19 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,037] INFO [ProducerStateManager partition=multi-broker-topic-2] Loading producer state from snapshot file 'SnapshotFile(offset=19, file=D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-2\00000000000000000019.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:46:41,059] INFO [LogLoader partition=multi-broker-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Producer state recovery took 22ms for snapshot load and 0ms for segment recovery from offset 19 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,085] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-2, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=19) with 1 segments, local-log-start-offset 0 and log-end-offset 19 in 152ms (1/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,115] INFO [LogLoader partition=test-topic-1, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,123] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\test-topic-1, topicId=REe8ARNrTE2yDJNN0Y2ywA, topic=test-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 37ms (2/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,147] INFO [LogLoader partition=test-topic-4, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,155] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\test-topic-4, topicId=REe8ARNrTE2yDJNN0Y2ywA, topic=test-topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 31ms (3/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,182] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,182] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\kafka\__manual-logs__\server2-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,184] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-1\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:46:41,193] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\kafka\__manual-logs__\server2-logs] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,204] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-1, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 49ms (4/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,231] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,238] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-10, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 34ms (5/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,255] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,262] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-13, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 23ms (6/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,277] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,284] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-16, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 22ms (7/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,300] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,307] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-19, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 22ms (8/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,322] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,329] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-22, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 22ms (9/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,344] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,350] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-25, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 21ms (10/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,368] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,377] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-28, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 26ms (11/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,421] INFO Deleted producer state snapshot D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-31\00000000000000000001.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-09-06 15:46:41,421] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,422] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\kafka\__manual-logs__\server2-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,426] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-31\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:46:41,432] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\kafka\__manual-logs__\server2-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,438] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-31, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 60ms (12/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,455] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,463] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-34, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 25ms (13/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,487] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,496] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-37, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 32ms (14/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,522] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,522] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\kafka\__manual-logs__\server2-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,524] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-4\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 15:46:41,532] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\kafka\__manual-logs__\server2-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,537] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-4, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 41ms (15/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,556] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,566] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-40, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 27ms (16/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,584] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,591] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-43, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 25ms (17/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,606] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,612] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-46, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 21ms (18/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,626] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,633] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-49, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (19/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,649] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:46:41,655] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-7, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 22ms (20/20 completed in D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:46:41,660] INFO Loaded 20 logs in 768ms (kafka.log.LogManager)
[2024-09-06 15:46:41,665] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 15:46:41,666] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 15:46:41,804] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:46:41,824] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:46:41,850] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 15:46:41,887] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:42,267] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 15:46:42,302] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 15:46:42,319] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:42,360] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:42,363] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:42,366] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:42,367] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:42,367] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:42,385] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:46:42,386] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:46:42,469] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 15:46:42,489] INFO Stat of the created znode at /brokers/ids/2 is: 475,475,1725617802482,1725617802482,1,0,0,72120726200582146,202,0,475
 (kafka.zk.KafkaZkClient)
[2024-09-06 15:46:42,490] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://localhost:9094, czxid (broker epoch): 475 (kafka.zk.KafkaZkClient)
[2024-09-06 15:46:42,515] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:42,515] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:42,519] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:42,567] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:42,580] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:42,581] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:42,603] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:42,621] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:42,634] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:42,640] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:42,641] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:42,673] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:46:42,678] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:46:42,679] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:46:42,739] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:46:42,763] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:42,766] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:42,767] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:46:42,793] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:46:42,823] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 15:46:42,827] INFO Awaiting socket connections on localhost:9094. (kafka.network.DataPlaneAcceptor)
[2024-09-06 15:46:42,831] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:46:42,832] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:46:42,837] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:46:42,838] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:46:42,844] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:46:42,845] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:46:42,846] INFO Kafka startTimeMs: 1725617802839 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:46:42,849] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2024-09-06 15:46:42,973] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:42,981] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:46:43,013] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,014] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,015] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,018] INFO [Partition test-topic-1 broker=2] Log loaded for partition test-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,018] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,019] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 3 (kafka.cluster.Partition)
[2024-09-06 15:46:43,019] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,020] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 3 (kafka.cluster.Partition)
[2024-09-06 15:46:43,020] INFO [Partition multi-broker-topic-2 broker=2] Log loaded for partition multi-broker-topic-2 with initial high watermark 19 (kafka.cluster.Partition)
[2024-09-06 15:46:43,020] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,021] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,021] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,022] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 3 (kafka.cluster.Partition)
[2024-09-06 15:46:43,022] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,023] INFO [Partition test-topic-4 broker=2] Log loaded for partition test-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,023] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,023] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,024] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,024] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,025] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:46:43,052] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, multi-broker-topic-2, test-topic-1, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, test-topic-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:46:43,160] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,161] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,163] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,165] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,165] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,165] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,166] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,166] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,167] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,168] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,168] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,169] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 5 milliseconds for epoch 4, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,169] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,169] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,170] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,171] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 4 milliseconds for epoch 4, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,171] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,173] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,177] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,179] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,180] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,181] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,182] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,182] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,183] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,183] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,183] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,184] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,184] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,185] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,185] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,185] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,186] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,186] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,187] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,187] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,188] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,192] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,196] INFO Loaded member MemberMetadata(memberId=console-consumer-f5ecfca5-7f85-4ba2-8512-718a3f008e54, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-18641 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 15:46:43,203] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 35 milliseconds for epoch 4, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,203] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 33 milliseconds for epoch 4, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,209] INFO Loaded member MemberMetadata(memberId=console-consumer-95e2877d-8e16-476a-a99e-cdeb0f5d86dd, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-35147 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 15:46:43,210] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 33 milliseconds for epoch 4, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,211] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 31 milliseconds for epoch 4, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,212] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 30 milliseconds for epoch 4, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,212] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 30 milliseconds for epoch 4, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,217] INFO Loaded member MemberMetadata(memberId=console-consumer-89e59505-d0d2-41a3-8b0f-d2e2d64dab2d, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-67901 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 15:46:43,218] INFO Loaded member MemberMetadata(memberId=console-consumer-89e59505-d0d2-41a3-8b0f-d2e2d64dab2d, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-67901 with generation 2. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 15:46:43,222] INFO [GroupCoordinator 2]: Loading group metadata for console-consumer-67901 with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:46:43,222] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 39 milliseconds for epoch 4, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,223] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 39 milliseconds for epoch 4, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,224] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 39 milliseconds for epoch 4, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,225] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 38 milliseconds for epoch 4, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,225] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 38 milliseconds for epoch 4, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 38 milliseconds for epoch 4, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:46:43,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 33 milliseconds for epoch 4, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:47:25,135] ERROR Error while reading checkpoint file D:\kafka\__manual-logs__\server0-logs\cleaner-offset-checkpoint (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.NoSuchFileException: D:\kafka\__manual-logs__\server0-logs\cleaner-offset-checkpoint
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:85)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.newByteChannel(WindowsFileSystemProvider.java:236)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:380)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:432)
	at java.base/java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:422)
	at java.base/java.nio.file.Files.newInputStream(Files.java:160)
	at java.base/java.nio.file.Files.newBufferedReader(Files.java:2921)
	at org.apache.kafka.server.common.CheckpointFile.read(CheckpointFile.java:92)
	at org.apache.kafka.storage.internals.checkpoint.CheckpointFileWithFailureHandler.read(CheckpointFileWithFailureHandler.java:74)
	at kafka.server.checkpoints.OffsetCheckpointFile.read(OffsetCheckpointFile.scala:75)
	at kafka.log.LogCleanerManager.$anonfun$allCleanerCheckpoints$2(LogCleanerManager.scala:147)
	at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.immutable.List$.from(List.scala:685)
	at scala.collection.immutable.List$.from(List.scala:682)
	at scala.collection.IterableFactory$Delegate.from(Factory.scala:288)
	at scala.collection.immutable.Iterable$.from(Iterable.scala:35)
	at scala.collection.immutable.Iterable$.from(Iterable.scala:32)
	at scala.collection.IterableFactory$Delegate.from(Factory.scala:288)
	at scala.collection.IterableOps.flatMap(Iterable.scala:686)
	at scala.collection.IterableOps.flatMap$(Iterable.scala:686)
	at scala.collection.AbstractIterable.flatMap(Iterable.scala:935)
	at kafka.log.LogCleanerManager.$anonfun$allCleanerCheckpoints$1(LogCleanerManager.scala:145)
	at kafka.log.LogCleanerManager.allCleanerCheckpoints(LogCleanerManager.scala:153)
	at kafka.log.LogCleanerManager.$anonfun$grabFilthiestCompactedLog$1(LogCleanerManager.scala:184)
	at kafka.log.LogCleanerManager.grabFilthiestCompactedLog(LogCleanerManager.scala:181)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:405)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:392)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:378)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:135)
[2024-09-06 15:47:25,138] WARN [ReplicaManager broker=0] Stopping serving replicas in dir D:\kafka\__manual-logs__\server0-logs with uuid None because the log directory has failed. (kafka.server.ReplicaManager)
[2024-09-06 15:47:25,139] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, test-topic-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, multi-broker-topic-4, __consumer_offsets-48, multi-broker-topic-5, test-topic-0, __consumer_offsets-39, __consumer_offsets-12, multi-broker-topic-1, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:47:25,140] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, test-topic-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, multi-broker-topic-4, __consumer_offsets-48, multi-broker-topic-5, test-topic-0, __consumer_offsets-39, __consumer_offsets-12, multi-broker-topic-1, __consumer_offsets-45) (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 15:47:25,149] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-30,__consumer_offsets-21,__consumer_offsets-33,__consumer_offsets-36,__consumer_offsets-6,__consumer_offsets-0,__consumer_offsets-27,__consumer_offsets-9,__consumer_offsets-42,__consumer_offsets-3,test-topic-3,__consumer_offsets-18,__consumer_offsets-15,__consumer_offsets-24,multi-broker-topic-4,__consumer_offsets-48,multi-broker-topic-5,test-topic-0,__consumer_offsets-39,__consumer_offsets-12,multi-broker-topic-1,__consumer_offsets-45 and stopped moving logs for partitions  because they are in the failed log directory D:\kafka\__manual-logs__\server0-logs. (kafka.server.ReplicaManager)
[2024-09-06 15:47:25,149] WARN Stopping serving logs in dir D:\kafka\__manual-logs__\server0-logs (kafka.log.LogManager)
[2024-09-06 15:47:25,152] ERROR Shutdown broker because all log dirs in D:\kafka\__manual-logs__\server0-logs have failed (kafka.log.LogManager)
[2024-09-06 15:47:25,654] WARN Close of session 0x100396b1a210000 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
[2024-09-06 15:47:35,996] ERROR Error while reading checkpoint file D:\kafka\__manual-logs__\server1-logs\cleaner-offset-checkpoint (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.NoSuchFileException: D:\kafka\__manual-logs__\server1-logs\cleaner-offset-checkpoint
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:85)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.newByteChannel(WindowsFileSystemProvider.java:236)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:380)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:432)
	at java.base/java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:422)
	at java.base/java.nio.file.Files.newInputStream(Files.java:160)
	at java.base/java.nio.file.Files.newBufferedReader(Files.java:2921)
	at org.apache.kafka.server.common.CheckpointFile.read(CheckpointFile.java:92)
	at org.apache.kafka.storage.internals.checkpoint.CheckpointFileWithFailureHandler.read(CheckpointFileWithFailureHandler.java:74)
	at kafka.server.checkpoints.OffsetCheckpointFile.read(OffsetCheckpointFile.scala:75)
	at kafka.log.LogCleanerManager.$anonfun$allCleanerCheckpoints$2(LogCleanerManager.scala:147)
	at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.immutable.List$.from(List.scala:685)
	at scala.collection.immutable.List$.from(List.scala:682)
	at scala.collection.IterableFactory$Delegate.from(Factory.scala:288)
	at scala.collection.immutable.Iterable$.from(Iterable.scala:35)
	at scala.collection.immutable.Iterable$.from(Iterable.scala:32)
	at scala.collection.IterableFactory$Delegate.from(Factory.scala:288)
	at scala.collection.IterableOps.flatMap(Iterable.scala:686)
	at scala.collection.IterableOps.flatMap$(Iterable.scala:686)
	at scala.collection.AbstractIterable.flatMap(Iterable.scala:935)
	at kafka.log.LogCleanerManager.$anonfun$allCleanerCheckpoints$1(LogCleanerManager.scala:145)
	at kafka.log.LogCleanerManager.allCleanerCheckpoints(LogCleanerManager.scala:153)
	at kafka.log.LogCleanerManager.$anonfun$grabFilthiestCompactedLog$1(LogCleanerManager.scala:184)
	at kafka.log.LogCleanerManager.grabFilthiestCompactedLog(LogCleanerManager.scala:181)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:405)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:392)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:378)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:135)
[2024-09-06 15:47:36,000] WARN [ReplicaManager broker=1] Stopping serving replicas in dir D:\kafka\__manual-logs__\server1-logs with uuid None because the log directory has failed. (kafka.server.ReplicaManager)
[2024-09-06 15:47:36,001] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(multi-broker-topic-0, __consumer_offsets-35, test-topic-2, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, multi-broker-topic-3, __consumer_offsets-8, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:47:36,002] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions HashSet(multi-broker-topic-0, __consumer_offsets-35, test-topic-2, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, multi-broker-topic-3, __consumer_offsets-8, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 15:47:36,010] WARN [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions multi-broker-topic-0,__consumer_offsets-35,test-topic-2,__consumer_offsets-47,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-11,__consumer_offsets-29,__consumer_offsets-32,multi-broker-topic-3,__consumer_offsets-8,__consumer_offsets-41,__consumer_offsets-23,__consumer_offsets-2,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-44,__consumer_offsets-5,__consumer_offsets-26 and stopped moving logs for partitions  because they are in the failed log directory D:\kafka\__manual-logs__\server1-logs. (kafka.server.ReplicaManager)
[2024-09-06 15:47:36,012] WARN Stopping serving logs in dir D:\kafka\__manual-logs__\server1-logs (kafka.log.LogManager)
[2024-09-06 15:47:36,014] ERROR Shutdown broker because all log dirs in D:\kafka\__manual-logs__\server1-logs have failed (kafka.log.LogManager)
[2024-09-06 15:47:36,514] WARN Close of session 0x100396b1a210001 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
[2024-09-06 15:47:43,031] INFO Expiring session 0x100396b1a210000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:47:43,137] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,139] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,142] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,258] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,258] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,259] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,364] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,364] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,365] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,471] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,471] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,471] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,579] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,579] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,580] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,686] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,686] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,687] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,795] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,796] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,796] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,902] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,902] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:43,902] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,011] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,012] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,016] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,132] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,132] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,133] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,239] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,239] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,240] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,347] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,348] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,350] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,455] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,455] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,456] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,562] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,562] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,563] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,670] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,670] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,670] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,780] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,780] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,780] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,887] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,887] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,888] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,993] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,994] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:44,994] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,102] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,102] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,103] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,208] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,208] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,209] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,314] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,315] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,316] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,422] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,422] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,423] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,529] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,529] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,530] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,638] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,639] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,639] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,745] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,746] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,746] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,852] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,852] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,853] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,960] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,960] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:45,961] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,068] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,068] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,069] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,177] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,177] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,178] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,286] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,286] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,288] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,393] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,393] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,394] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,501] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,501] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,502] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,608] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,608] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,608] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,715] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,715] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,716] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,824] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,824] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,824] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,933] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,933] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:46,933] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,040] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,041] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,041] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,148] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,148] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,149] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,254] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,254] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,255] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,362] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,363] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,363] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,470] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,471] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,471] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,577] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,577] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,578] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,685] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,685] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,687] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,794] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,794] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,795] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,900] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,900] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:47,900] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,009] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,010] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,011] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,116] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,116] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,118] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,224] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,224] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,226] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,333] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,333] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,333] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,441] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,441] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,442] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,547] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,549] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,549] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,656] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,656] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,658] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,765] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,765] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,767] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,873] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,873] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,874] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,981] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,981] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:48,982] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:49,031] INFO Expiring session 0x100396b1a210001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:47:49,040] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:47:56,869] ERROR Error while reading checkpoint file D:\kafka\__manual-logs__\server2-logs\cleaner-offset-checkpoint (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.NoSuchFileException: D:\kafka\__manual-logs__\server2-logs\cleaner-offset-checkpoint
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:85)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.newByteChannel(WindowsFileSystemProvider.java:236)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:380)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:432)
	at java.base/java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:422)
	at java.base/java.nio.file.Files.newInputStream(Files.java:160)
	at java.base/java.nio.file.Files.newBufferedReader(Files.java:2921)
	at org.apache.kafka.server.common.CheckpointFile.read(CheckpointFile.java:92)
	at org.apache.kafka.storage.internals.checkpoint.CheckpointFileWithFailureHandler.read(CheckpointFileWithFailureHandler.java:74)
	at kafka.server.checkpoints.OffsetCheckpointFile.read(OffsetCheckpointFile.scala:75)
	at kafka.log.LogCleanerManager.$anonfun$allCleanerCheckpoints$2(LogCleanerManager.scala:147)
	at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.immutable.List$.from(List.scala:685)
	at scala.collection.immutable.List$.from(List.scala:682)
	at scala.collection.IterableFactory$Delegate.from(Factory.scala:288)
	at scala.collection.immutable.Iterable$.from(Iterable.scala:35)
	at scala.collection.immutable.Iterable$.from(Iterable.scala:32)
	at scala.collection.IterableFactory$Delegate.from(Factory.scala:288)
	at scala.collection.IterableOps.flatMap(Iterable.scala:686)
	at scala.collection.IterableOps.flatMap$(Iterable.scala:686)
	at scala.collection.AbstractIterable.flatMap(Iterable.scala:935)
	at kafka.log.LogCleanerManager.$anonfun$allCleanerCheckpoints$1(LogCleanerManager.scala:145)
	at kafka.log.LogCleanerManager.allCleanerCheckpoints(LogCleanerManager.scala:153)
	at kafka.log.LogCleanerManager.$anonfun$grabFilthiestCompactedLog$1(LogCleanerManager.scala:184)
	at kafka.log.LogCleanerManager.grabFilthiestCompactedLog(LogCleanerManager.scala:181)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:405)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:392)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:378)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:135)
[2024-09-06 15:47:56,871] WARN [ReplicaManager broker=2] Stopping serving replicas in dir D:\kafka\__manual-logs__\server2-logs with uuid None because the log directory has failed. (kafka.server.ReplicaManager)
[2024-09-06 15:47:56,872] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, multi-broker-topic-2, test-topic-1, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, test-topic-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:47:56,873] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, multi-broker-topic-2, test-topic-1, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, test-topic-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 15:47:56,881] WARN [ReplicaManager broker=2] Broker 2 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-4,__consumer_offsets-25,__consumer_offsets-49,__consumer_offsets-31,__consumer_offsets-37,multi-broker-topic-2,test-topic-1,__consumer_offsets-19,__consumer_offsets-13,__consumer_offsets-43,__consumer_offsets-1,__consumer_offsets-34,__consumer_offsets-7,test-topic-4,__consumer_offsets-46,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-10,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory D:\kafka\__manual-logs__\server2-logs. (kafka.server.ReplicaManager)
[2024-09-06 15:47:56,881] WARN Stopping serving logs in dir D:\kafka\__manual-logs__\server2-logs (kafka.log.LogManager)
[2024-09-06 15:47:56,884] ERROR Shutdown broker because all log dirs in D:\kafka\__manual-logs__\server2-logs have failed (kafka.log.LogManager)
[2024-09-06 15:47:57,389] WARN Close of session 0x100396b1a210002 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
[2024-09-06 15:48:16,030] INFO Expiring session 0x100396b1a210002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 15:48:17,124] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 15:48:17,463] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 15:48:17,467] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:17,609] INFO starting (kafka.server.KafkaServer)
[2024-09-06 15:48:17,610] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 15:48:17,631] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:48:17,635] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,635] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,637] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,637] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,638] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,638] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,639] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,640] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,640] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,641] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,641] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,642] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,642] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,644] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,644] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,644] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,646] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,646] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,648] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:17,702] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 15:48:17,712] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:17,713] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:48:17,715] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:17,719] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:58230, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:17,724] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100396b1a210003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:17,729] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:48:17,933] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 15:48:17,939] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:17,976] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:17,984] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server0-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 15:48:17,987] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:18,022] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:18,024] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:18,027] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:18,030] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:18,037] INFO [KafkaServer id=0] Rewriting D:\kafka\__manual-logs__\server0-logs\meta.properties (kafka.server.KafkaServer)
[2024-09-06 15:48:18,128] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 15:48:18,137] INFO No logs found to be loaded in D:\kafka\__manual-logs__\server0-logs (kafka.log.LogManager)
[2024-09-06 15:48:18,149] INFO Loaded 0 logs in 21ms (kafka.log.LogManager)
[2024-09-06 15:48:18,152] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 15:48:18,154] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 15:48:18,226] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:48:18,240] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:48:18,254] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 15:48:18,281] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:18,604] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 15:48:18,633] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 15:48:18,644] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:18,676] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:18,679] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:18,679] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:18,682] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:18,682] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:18,698] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:48:18,698] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:48:18,740] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 15:48:18,754] INFO Stat of the created znode at /brokers/ids/0 is: 557,557,1725617898749,1725617898749,1,0,0,72120726200582147,202,0,557
 (kafka.zk.KafkaZkClient)
[2024-09-06 15:48:18,754] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9092, czxid (broker epoch): 557 (kafka.zk.KafkaZkClient)
[2024-09-06 15:48:18,807] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:18,817] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:18,817] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:18,838] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:18,858] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:18,884] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:48:18,890] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:48:18,890] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:48:18,952] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:18,962] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:18,966] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:18,971] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:18,996] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:48:19,041] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 15:48:19,046] INFO Awaiting socket connections on localhost:9092. (kafka.network.DataPlaneAcceptor)
[2024-09-06 15:48:19,051] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:48:19,055] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:48:19,057] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:48:19,059] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:48:19,063] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:48:19,064] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:48:19,064] INFO Kafka startTimeMs: 1725617899060 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:48:19,069] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-09-06 15:48:19,146] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:19,191] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:19,278] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,291] INFO Created log for partition __consumer_offsets-3 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,297] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,308] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,309] INFO Created log for partition __consumer_offsets-18 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,309] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,323] INFO [LogLoader partition=multi-broker-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,323] INFO Created log for partition multi-broker-topic-1 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-1 with properties {} (kafka.log.LogManager)
[2024-09-06 15:48:19,323] INFO [Partition multi-broker-topic-1 broker=0] Log loaded for partition multi-broker-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,337] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,338] INFO Created log for partition __consumer_offsets-39 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,339] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,353] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,354] INFO Created log for partition __consumer_offsets-9 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,354] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,368] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,369] INFO Created log for partition __consumer_offsets-24 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,369] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,389] INFO [LogLoader partition=test-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,389] INFO Created log for partition test-topic-3 in D:\kafka\__manual-logs__\server0-logs\test-topic-3 with properties {} (kafka.log.LogManager)
[2024-09-06 15:48:19,389] INFO [Partition test-topic-3 broker=0] Log loaded for partition test-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,406] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,407] INFO Created log for partition __consumer_offsets-27 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,407] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,422] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,423] INFO Created log for partition __consumer_offsets-42 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,423] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,439] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,440] INFO Created log for partition __consumer_offsets-12 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,440] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,456] INFO [LogLoader partition=multi-broker-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,457] INFO Created log for partition multi-broker-topic-4 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-4 with properties {} (kafka.log.LogManager)
[2024-09-06 15:48:19,458] INFO [Partition multi-broker-topic-4 broker=0] Log loaded for partition multi-broker-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,474] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,475] INFO Created log for partition __consumer_offsets-33 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,475] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,491] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,492] INFO Created log for partition __consumer_offsets-48 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,492] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,506] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,508] INFO Created log for partition __consumer_offsets-21 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,508] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,522] INFO [LogLoader partition=test-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,522] INFO Created log for partition test-topic-0 in D:\kafka\__manual-logs__\server0-logs\test-topic-0 with properties {} (kafka.log.LogManager)
[2024-09-06 15:48:19,523] INFO [Partition test-topic-0 broker=0] Log loaded for partition test-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,538] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,538] INFO Created log for partition __consumer_offsets-36 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,539] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,553] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,553] INFO Created log for partition __consumer_offsets-6 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,554] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,567] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,568] INFO Created log for partition __consumer_offsets-45 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,568] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,583] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,584] INFO Created log for partition __consumer_offsets-15 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,584] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,600] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,600] INFO Created log for partition __consumer_offsets-30 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,601] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,614] INFO [LogLoader partition=multi-broker-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,615] INFO Created log for partition multi-broker-topic-5 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-5 with properties {} (kafka.log.LogManager)
[2024-09-06 15:48:19,615] INFO [Partition multi-broker-topic-5 broker=0] Log loaded for partition multi-broker-topic-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,631] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:19,632] INFO Created log for partition __consumer_offsets-0 in D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:19,632] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:19,666] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, test-topic-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, multi-broker-topic-4, __consumer_offsets-48, multi-broker-topic-5, test-topic-0, __consumer_offsets-39, __consumer_offsets-12, multi-broker-topic-1, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:48:19,755] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,756] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,760] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,760] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,761] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,762] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,762] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,763] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,763] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,764] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,764] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,764] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 4 milliseconds for epoch 6, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,765] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,765] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 3 milliseconds for epoch 6, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,766] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,767] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 4 milliseconds for epoch 6, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,768] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,768] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 4 milliseconds for epoch 6, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,769] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,769] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 3 milliseconds for epoch 6, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,769] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,770] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,770] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,771] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,771] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,772] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,772] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,773] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,774] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,774] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,775] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,775] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,776] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,778] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,778] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,781] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,783] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,783] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,783] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,784] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,785] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,785] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,786] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,786] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,786] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,787] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:19,788] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,788] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:19,789] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:25,471] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 15:48:25,769] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 15:48:25,772] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:25,888] INFO starting (kafka.server.KafkaServer)
[2024-09-06 15:48:25,889] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 15:48:25,902] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:48:25,906] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,906] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,907] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,909] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,909] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,912] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,913] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,913] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,914] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,914] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,915] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,915] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,915] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,916] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,916] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,917] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,917] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,918] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,920] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@10f7f7de (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:25,968] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 15:48:25,975] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:25,977] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:48:25,979] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:25,983] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:58236, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:25,988] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100396b1a210004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:25,993] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:48:26,184] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 15:48:26,188] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:26,235] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:26,247] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server1-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 15:48:26,251] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:26,288] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:26,290] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:26,290] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:26,301] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:26,304] INFO [KafkaServer id=1] Rewriting D:\kafka\__manual-logs__\server1-logs\meta.properties (kafka.server.KafkaServer)
[2024-09-06 15:48:26,419] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server1-logs) (kafka.log.LogManager)
[2024-09-06 15:48:26,435] INFO No logs found to be loaded in D:\kafka\__manual-logs__\server1-logs (kafka.log.LogManager)
[2024-09-06 15:48:26,452] INFO Loaded 0 logs in 32ms (kafka.log.LogManager)
[2024-09-06 15:48:26,453] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 15:48:26,455] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 15:48:26,541] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:48:26,554] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:48:26,566] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 15:48:26,590] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:26,898] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 15:48:26,928] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 15:48:26,935] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:26,963] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:26,965] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:26,968] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:26,968] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:26,968] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:26,981] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:48:26,981] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:48:27,027] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 15:48:27,037] INFO Stat of the created znode at /brokers/ids/1 is: 636,636,1725617907033,1725617907033,1,0,0,72120726200582148,202,0,636
 (kafka.zk.KafkaZkClient)
[2024-09-06 15:48:27,038] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9093, czxid (broker epoch): 636 (kafka.zk.KafkaZkClient)
[2024-09-06 15:48:27,050] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:27,050] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:27,052] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:27,100] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:27,113] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:27,113] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:27,129] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,146] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,167] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:48:27,168] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:27,171] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:48:27,169] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:27,171] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:48:27,178] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:27,226] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:27,252] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:48:27,267] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 15:48:27,270] INFO Awaiting socket connections on localhost:9093. (kafka.network.DataPlaneAcceptor)
[2024-09-06 15:48:27,274] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:48:27,274] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:48:27,277] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:48:27,277] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:48:27,281] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:48:27,282] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:48:27,282] INFO Kafka startTimeMs: 1725617907279 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:48:27,283] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2024-09-06 15:48:27,353] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:27,368] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:27,487] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,504] INFO Created log for partition __consumer_offsets-35 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,510] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2024-09-06 15:48:27,513] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,529] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,530] INFO Created log for partition __consumer_offsets-5 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,530] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2024-09-06 15:48:27,531] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,549] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,549] INFO Created log for partition __consumer_offsets-20 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,550] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2024-09-06 15:48:27,550] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,566] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,567] INFO Created log for partition __consumer_offsets-41 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,568] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2024-09-06 15:48:27,571] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,584] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,585] INFO Created log for partition __consumer_offsets-29 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,586] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2024-09-06 15:48:27,588] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,601] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,602] INFO Created log for partition __consumer_offsets-44 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,602] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2024-09-06 15:48:27,605] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,620] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,621] INFO Created log for partition __consumer_offsets-14 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,621] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2024-09-06 15:48:27,623] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,640] INFO [LogLoader partition=multi-broker-topic-0, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,642] INFO Created log for partition multi-broker-topic-0 in D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-0 with properties {} (kafka.log.LogManager)
[2024-09-06 15:48:27,646] INFO [Partition multi-broker-topic-0 broker=1] No checkpointed highwatermark is found for partition multi-broker-topic-0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,646] INFO [Partition multi-broker-topic-0 broker=1] Log loaded for partition multi-broker-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,663] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,664] INFO Created log for partition __consumer_offsets-2 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,664] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2024-09-06 15:48:27,664] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,678] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,679] INFO Created log for partition __consumer_offsets-23 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,679] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2024-09-06 15:48:27,680] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,691] INFO [LogLoader partition=test-topic-2, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,692] INFO Created log for partition test-topic-2 in D:\kafka\__manual-logs__\server1-logs\test-topic-2 with properties {} (kafka.log.LogManager)
[2024-09-06 15:48:27,693] INFO [Partition test-topic-2 broker=1] No checkpointed highwatermark is found for partition test-topic-2 (kafka.cluster.Partition)
[2024-09-06 15:48:27,694] INFO [Partition test-topic-2 broker=1] Log loaded for partition test-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,706] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,707] INFO Created log for partition __consumer_offsets-38 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,710] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2024-09-06 15:48:27,710] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,721] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,722] INFO Created log for partition __consumer_offsets-8 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,722] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2024-09-06 15:48:27,726] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,739] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,740] INFO Created log for partition __consumer_offsets-11 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,740] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2024-09-06 15:48:27,743] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,754] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,754] INFO Created log for partition __consumer_offsets-26 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,755] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2024-09-06 15:48:27,757] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,770] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,770] INFO Created log for partition __consumer_offsets-47 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,771] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2024-09-06 15:48:27,773] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,787] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,788] INFO Created log for partition __consumer_offsets-17 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,789] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2024-09-06 15:48:27,792] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,803] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,804] INFO Created log for partition __consumer_offsets-32 in D:\kafka\__manual-logs__\server1-logs\__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:27,804] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2024-09-06 15:48:27,806] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,818] INFO [LogLoader partition=multi-broker-topic-3, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:27,818] INFO Created log for partition multi-broker-topic-3 in D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-3 with properties {} (kafka.log.LogManager)
[2024-09-06 15:48:27,819] INFO [Partition multi-broker-topic-3 broker=1] No checkpointed highwatermark is found for partition multi-broker-topic-3 (kafka.cluster.Partition)
[2024-09-06 15:48:27,821] INFO [Partition multi-broker-topic-3 broker=1] Log loaded for partition multi-broker-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:27,842] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(multi-broker-topic-0, __consumer_offsets-35, test-topic-2, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, multi-broker-topic-3, __consumer_offsets-8, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:48:27,942] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,943] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,945] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,946] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,948] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,948] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,949] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,949] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,950] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,950] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,951] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,951] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,952] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,952] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,952] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 7 milliseconds for epoch 5, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,952] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,954] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 6 milliseconds for epoch 5, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,954] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,955] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 6 milliseconds for epoch 5, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,955] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,956] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 6 milliseconds for epoch 5, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,956] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,957] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 6 milliseconds for epoch 5, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,957] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,959] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 6 milliseconds for epoch 5, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,959] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,960] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 8 milliseconds for epoch 5, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,960] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,961] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 6 milliseconds for epoch 5, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,962] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,963] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 6 milliseconds for epoch 5, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,963] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,963] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 3 milliseconds for epoch 5, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,964] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,964] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds for epoch 5, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,965] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,966] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds for epoch 5, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,966] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,972] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,972] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds for epoch 5, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,973] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,974] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,974] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,974] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds for epoch 5, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,975] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:27,977] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 2 milliseconds for epoch 5, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,978] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:27,982] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds for epoch 5, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:29,186] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 15:48:29,458] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 15:48:29,461] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:29,567] INFO starting (kafka.server.KafkaServer)
[2024-09-06 15:48:29,568] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 15:48:29,582] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:48:29,587] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,587] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,587] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,588] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,588] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,588] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,589] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,590] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,590] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,591] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,592] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,592] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,592] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,593] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,593] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,594] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,594] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,595] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,598] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 15:48:29,643] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 15:48:29,652] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:29,654] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:48:29,655] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:29,660] INFO Socket connection established, initiating session, client: /127.0.0.1:58242, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:29,665] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100396b1a210005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 15:48:29,669] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 15:48:29,868] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 15:48:29,875] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:29,909] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:29,916] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server2-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 15:48:29,920] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 15:48:29,952] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:29,953] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:29,953] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:29,956] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 15:48:29,962] INFO [KafkaServer id=2] Rewriting D:\kafka\__manual-logs__\server2-logs\meta.properties (kafka.server.KafkaServer)
[2024-09-06 15:48:30,047] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server2-logs) (kafka.log.LogManager)
[2024-09-06 15:48:30,056] INFO No logs found to be loaded in D:\kafka\__manual-logs__\server2-logs (kafka.log.LogManager)
[2024-09-06 15:48:30,068] INFO Loaded 0 logs in 19ms (kafka.log.LogManager)
[2024-09-06 15:48:30,069] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 15:48:30,070] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 15:48:30,144] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 15:48:30,158] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 15:48:30,171] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 15:48:30,198] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:30,520] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 15:48:30,553] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 15:48:30,562] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:30,590] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:30,592] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:30,594] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:30,594] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:30,598] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:30,609] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 15:48:30,609] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 15:48:30,662] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 15:48:30,676] INFO Stat of the created znode at /brokers/ids/2 is: 671,671,1725617910672,1725617910672,1,0,0,72120726200582149,202,0,671
 (kafka.zk.KafkaZkClient)
[2024-09-06 15:48:30,677] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://localhost:9094, czxid (broker epoch): 671 (kafka.zk.KafkaZkClient)
[2024-09-06 15:48:30,684] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:30,684] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:30,687] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:30,732] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:30,741] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:30,742] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:30,759] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:30,777] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:30,796] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:48:30,799] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 15:48:30,799] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 15:48:30,810] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:30,810] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:30,812] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:48:30,845] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 15:48:30,869] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 15:48:30,887] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 15:48:30,890] INFO Awaiting socket connections on localhost:9094. (kafka.network.DataPlaneAcceptor)
[2024-09-06 15:48:30,896] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:48:30,896] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 15:48:30,896] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:48:30,897] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 15:48:30,899] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:48:30,899] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:48:30,899] INFO Kafka startTimeMs: 1725617910897 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 15:48:30,901] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2024-09-06 15:48:30,993] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:31,070] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 15:48:31,084] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,096] INFO Created log for partition __consumer_offsets-37 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,099] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2024-09-06 15:48:31,101] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,115] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,117] INFO Created log for partition __consumer_offsets-7 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,118] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2024-09-06 15:48:31,120] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,134] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,135] INFO Created log for partition __consumer_offsets-22 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,135] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2024-09-06 15:48:31,137] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,153] INFO [LogLoader partition=test-topic-1, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,153] INFO Created log for partition test-topic-1 in D:\kafka\__manual-logs__\server2-logs\test-topic-1 with properties {} (kafka.log.LogManager)
[2024-09-06 15:48:31,153] INFO [Partition test-topic-1 broker=2] No checkpointed highwatermark is found for partition test-topic-1 (kafka.cluster.Partition)
[2024-09-06 15:48:31,156] INFO [Partition test-topic-1 broker=2] Log loaded for partition test-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,172] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,173] INFO Created log for partition __consumer_offsets-10 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,175] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2024-09-06 15:48:31,176] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,192] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,193] INFO Created log for partition __consumer_offsets-31 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,193] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2024-09-06 15:48:31,197] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,210] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,211] INFO Created log for partition __consumer_offsets-46 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,211] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2024-09-06 15:48:31,214] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,230] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,230] INFO Created log for partition __consumer_offsets-1 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,231] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2024-09-06 15:48:31,233] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,248] INFO [LogLoader partition=multi-broker-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,249] INFO Created log for partition multi-broker-topic-2 in D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-2 with properties {} (kafka.log.LogManager)
[2024-09-06 15:48:31,249] INFO [Partition multi-broker-topic-2 broker=2] No checkpointed highwatermark is found for partition multi-broker-topic-2 (kafka.cluster.Partition)
[2024-09-06 15:48:31,250] INFO [Partition multi-broker-topic-2 broker=2] Log loaded for partition multi-broker-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,264] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,265] INFO Created log for partition __consumer_offsets-16 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,265] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2024-09-06 15:48:31,266] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,279] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,279] INFO Created log for partition __consumer_offsets-19 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,280] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2024-09-06 15:48:31,280] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,292] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,293] INFO Created log for partition __consumer_offsets-34 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,293] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2024-09-06 15:48:31,293] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,305] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,306] INFO Created log for partition __consumer_offsets-4 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,308] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2024-09-06 15:48:31,309] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,321] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,321] INFO Created log for partition __consumer_offsets-25 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,322] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2024-09-06 15:48:31,325] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,337] INFO [LogLoader partition=test-topic-4, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,338] INFO Created log for partition test-topic-4 in D:\kafka\__manual-logs__\server2-logs\test-topic-4 with properties {} (kafka.log.LogManager)
[2024-09-06 15:48:31,338] INFO [Partition test-topic-4 broker=2] No checkpointed highwatermark is found for partition test-topic-4 (kafka.cluster.Partition)
[2024-09-06 15:48:31,342] INFO [Partition test-topic-4 broker=2] Log loaded for partition test-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,353] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,354] INFO Created log for partition __consumer_offsets-40 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,354] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2024-09-06 15:48:31,356] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,369] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,370] INFO Created log for partition __consumer_offsets-43 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,370] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2024-09-06 15:48:31,373] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,384] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,385] INFO Created log for partition __consumer_offsets-13 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,385] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2024-09-06 15:48:31,388] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,401] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,402] INFO Created log for partition __consumer_offsets-28 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,402] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2024-09-06 15:48:31,404] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,416] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 15:48:31,417] INFO Created log for partition __consumer_offsets-49 in D:\kafka\__manual-logs__\server2-logs\__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2024-09-06 15:48:31,417] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2024-09-06 15:48:31,420] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 15:48:31,439] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, multi-broker-topic-2, test-topic-1, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, test-topic-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2024-09-06 15:48:31,520] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,521] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,523] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,525] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,525] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,526] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,526] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,527] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,527] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 4 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,527] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,528] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 3 milliseconds for epoch 6, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,528] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,529] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 3 milliseconds for epoch 6, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,529] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,530] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 3 milliseconds for epoch 6, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,530] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,533] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 4 milliseconds for epoch 6, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,533] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,535] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 2 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,535] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,535] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,536] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,536] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,537] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,537] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,537] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,538] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,538] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,539] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,540] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,540] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,540] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,541] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,541] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,542] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,542] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,542] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,543] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,543] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,544] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,544] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,544] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,545] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,544] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,545] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,546] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,549] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,551] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:48:31,551] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,551] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:48:31,552] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 15:49:37,728] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group console-consumer-90882 in Empty state. Created a new member id console-consumer-303a0f9b-ecbc-4ca3-b4fe-fcb9480252b3 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:49:37,745] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-90882 in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member console-consumer-303a0f9b-ecbc-4ca3-b4fe-fcb9480252b3 with group instance id None; client reason: need to re-join with the given member-id: console-consumer-303a0f9b-ecbc-4ca3-b4fe-fcb9480252b3) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:49:37,754] INFO [GroupCoordinator 0]: Stabilized group console-consumer-90882 generation 1 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:49:37,776] INFO [GroupCoordinator 0]: Assignment received from leader console-consumer-303a0f9b-ecbc-4ca3-b4fe-fcb9480252b3 for group console-consumer-90882 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 15:59:02,682] INFO [NodeToControllerChannelManager id=1 name=forwarding] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:59:19,359] INFO [NodeToControllerChannelManager id=0 name=forwarding] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 15:59:19,374] INFO [NodeToControllerChannelManager id=2 name=forwarding] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 16:30:12,363] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-90882 in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: Removing member console-consumer-303a0f9b-ecbc-4ca3-b4fe-fcb9480252b3 on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 16:30:12,366] INFO [GroupCoordinator 0]: Group console-consumer-90882 with generation 2 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 16:30:12,369] INFO [GroupCoordinator 0]: Member MemberMetadata(memberId=console-consumer-303a0f9b-ecbc-4ca3-b4fe-fcb9480252b3, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-90882 through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 16:38:18,868] INFO [GroupMetadataManager brokerId=0] Group console-consumer-90882 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 18:01:33,101] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group console-consumer-96964 in Empty state. Created a new member id console-consumer-40f12e9a-e3ab-491b-8602-b1d8f8a145f4 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 18:01:33,116] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-96964 in state PreparingRebalance with old generation 0 (__consumer_offsets-15) (reason: Adding new member console-consumer-40f12e9a-e3ab-491b-8602-b1d8f8a145f4 with group instance id None; client reason: need to re-join with the given member-id: console-consumer-40f12e9a-e3ab-491b-8602-b1d8f8a145f4) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 18:01:33,122] INFO [GroupCoordinator 0]: Stabilized group console-consumer-96964 generation 1 (__consumer_offsets-15) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 18:01:33,138] INFO [GroupCoordinator 0]: Assignment received from leader console-consumer-40f12e9a-e3ab-491b-8602-b1d8f8a145f4 for group console-consumer-96964 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 18:56:29,246] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:62411-4 (kafka.network.Processor)
[2024-09-06 18:56:29,255] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:62409-5 (kafka.network.Processor)
[2024-09-06 18:56:29,506] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9092-127.0.0.1:62410-6 (kafka.network.Processor)
[2024-09-06 18:56:30,309] WARN Client session timed out, have not heard from server in 989128ms for session id 0x100396b1a210005 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:30,235] WARN Client session timed out, have not heard from server in 989150ms for session id 0x100396b1a210003 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:30,692] WARN Session 0x100396b1a210003 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionTimeoutException: Client session timed out, have not heard from server in 989150ms for session id 0x100396b1a210003
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1257)
[2024-09-06 18:56:30,501] WARN Session 0x100396b1a210005 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionTimeoutException: Client session timed out, have not heard from server in 989128ms for session id 0x100396b1a210005
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1257)
[2024-09-06 18:56:30,349] INFO Expiring session 0x100396b1a210003, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 18:56:31,298] INFO Expiring session 0x100396b1a210004, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 18:56:31,009] INFO Unable to read additional data from client, it probably closed the socket: address = /127.0.0.1:58242, session = 0x100396b1a210005 (org.apache.zookeeper.server.NIOServerCnxn)
[2024-09-06 18:56:30,707] INFO Unable to read additional data from client, it probably closed the socket: address = /[0:0:0:0:0:0:0:1]:58230, session = 0x100396b1a210003 (org.apache.zookeeper.server.NIOServerCnxn)
[2024-09-06 18:56:31,308] INFO Expiring session 0x100396b1a210005, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 18:56:31,580] WARN Client session timed out, have not heard from server in 988029ms for session id 0x100396b1a210004 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:31,595] WARN Session 0x100396b1a210004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionTimeoutException: Client session timed out, have not heard from server in 988029ms for session id 0x100396b1a210004
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1257)
[2024-09-06 18:56:32,857] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:32,923] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:63089, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:32,979] INFO Invalid session 0x100396b1a210003 for client /[0:0:0:0:0:0:0:1]:63089, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 18:56:33,069] WARN Unable to reconnect to ZooKeeper service, session 0x100396b1a210003 has expired (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,130] WARN Session 0x100396b1a210003 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionExpiredException: Unable to reconnect to ZooKeeper service, session 0x100396b1a210003 has expired
	at org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1439)
	at org.apache.zookeeper.ClientCnxnSocket.readConnectResult(ClientCnxnSocket.java:154)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:86)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 18:56:33,073] INFO EventThread shut down for session: 0x100396b1a210003 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,182] INFO [ZooKeeperClient Kafka server] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 18:56:33,229] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 18:56:33,234] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,273] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 18:56:33,279] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:63095, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,392] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 18:56:33,423] INFO Invalid session 0x100396b1a210005 for client /[0:0:0:0:0:0:0:1]:63095, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 18:56:33,432] WARN Unable to reconnect to ZooKeeper service, session 0x100396b1a210005 has expired (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,435] INFO EventThread shut down for session: 0x100396b1a210005 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,450] WARN Session 0x100396b1a210005 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionExpiredException: Unable to reconnect to ZooKeeper service, session 0x100396b1a210005 has expired
	at org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1439)
	at org.apache.zookeeper.ClientCnxnSocket.readConnectResult(ClientCnxnSocket.java:154)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:86)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 18:56:33,452] INFO [ZooKeeperClient Kafka server] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 18:56:33,563] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 18:56:33,472] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,592] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,594] INFO Socket connection established, initiating session, client: /127.0.0.1:63098, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,575] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 18:56:33,608] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,613] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:63099, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,613] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100396b1a210006, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,616] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 18:56:33,625] INFO Invalid session 0x100396b1a210004 for client /[0:0:0:0:0:0:0:1]:63099, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2024-09-06 18:56:33,626] WARN Unable to reconnect to ZooKeeper service, session 0x100396b1a210004 has expired (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,627] INFO Stat of the created znode at /brokers/ids/0 is: 699,699,1725629193622,1725629193622,1,0,0,72120726200582150,202,0,699
 (kafka.zk.KafkaZkClient)
[2024-09-06 18:56:33,627] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9092, czxid (broker epoch): 699 (kafka.zk.KafkaZkClient)
[2024-09-06 18:56:33,627] WARN Session 0x100396b1a210004 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionExpiredException: Unable to reconnect to ZooKeeper service, session 0x100396b1a210004 has expired
	at org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1439)
	at org.apache.zookeeper.ClientCnxnSocket.readConnectResult(ClientCnxnSocket.java:154)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:86)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-09-06 18:56:33,630] INFO [MetadataCache brokerId=0] Updated cache from existing Some(Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0)) to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 18:56:33,631] INFO EventThread shut down for session: 0x100396b1a210004 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,635] INFO [ZooKeeperClient Kafka server] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 18:56:33,645] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 18:56:33,649] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,663] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 18:56:33,664] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@10f7f7de (org.apache.zookeeper.ZooKeeper)
[2024-09-06 18:56:33,731] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,744] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:63100, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,757] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100396b1a210007, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:33,792] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 18:56:33,793] INFO [MetadataCache brokerId=2] Updated cache from existing Some(Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0)) to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 18:56:33,798] INFO Stat of the created znode at /brokers/ids/2 is: 702,702,1725629193795,1725629193795,1,0,0,72120726200582151,202,0,702
 (kafka.zk.KafkaZkClient)
[2024-09-06 18:56:33,798] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://localhost:9094, czxid (broker epoch): 702 (kafka.zk.KafkaZkClient)
[2024-09-06 18:56:34,069] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 18:56:34,086] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:34,125] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:34,127] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:63106, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:34,140] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100396b1a210008, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 18:56:34,183] INFO [MetadataCache brokerId=1] Updated cache from existing Some(Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0)) to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 18:56:34,189] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 18:56:34,195] INFO Stat of the created znode at /brokers/ids/1 is: 704,704,1725629194192,1725629194192,1,0,0,72120726200582152,202,0,704
 (kafka.zk.KafkaZkClient)
[2024-09-06 18:56:34,195] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:9093, czxid (broker epoch): 704 (kafka.zk.KafkaZkClient)
[2024-09-06 18:56:35,009] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(multi-broker-topic-0, __consumer_offsets-35, test-topic-2, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, multi-broker-topic-3, __consumer_offsets-8, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2024-09-06 18:56:35,051] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, multi-broker-topic-2, test-topic-1, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, test-topic-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,465] INFO Creating topic multi-broker-topic-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(2, 1, 0), 1 -> ArrayBuffer(1, 0, 2), 2 -> ArrayBuffer(0, 2, 1), 3 -> ArrayBuffer(2, 0, 1), 4 -> ArrayBuffer(1, 2, 0), 5 -> ArrayBuffer(0, 1, 2), 6 -> ArrayBuffer(2, 1, 0)) (kafka.zk.AdminZkClient)
[2024-09-06 20:05:51,538] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:05:51,539] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:05:51,538] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:05:51,550] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(multi-broker-topic-topic-5, multi-broker-topic-topic-2) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,565] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(multi-broker-topic-topic-6, multi-broker-topic-topic-3, multi-broker-topic-topic-0) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,570] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(multi-broker-topic-topic-4, multi-broker-topic-topic-1) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,581] INFO [LogLoader partition=multi-broker-topic-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,584] INFO Created log for partition multi-broker-topic-topic-5 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-5 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,586] INFO [Partition multi-broker-topic-topic-5 broker=0] No checkpointed highwatermark is found for partition multi-broker-topic-topic-5 (kafka.cluster.Partition)
[2024-09-06 20:05:51,587] INFO [Partition multi-broker-topic-topic-5 broker=0] Log loaded for partition multi-broker-topic-topic-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,613] INFO [LogLoader partition=multi-broker-topic-topic-2, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,615] INFO Created log for partition multi-broker-topic-topic-2 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-2 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,616] INFO [Partition multi-broker-topic-topic-2 broker=0] No checkpointed highwatermark is found for partition multi-broker-topic-topic-2 (kafka.cluster.Partition)
[2024-09-06 20:05:51,616] INFO [Partition multi-broker-topic-topic-2 broker=0] Log loaded for partition multi-broker-topic-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,627] INFO [LogLoader partition=multi-broker-topic-topic-6, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,632] INFO Created log for partition multi-broker-topic-topic-6 in D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-topic-6 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,636] INFO [LogLoader partition=multi-broker-topic-topic-4, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,637] INFO [LogLoader partition=multi-broker-topic-topic-6, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,638] INFO Created log for partition multi-broker-topic-topic-6 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-6 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,638] INFO [Partition multi-broker-topic-topic-6 broker=0] No checkpointed highwatermark is found for partition multi-broker-topic-topic-6 (kafka.cluster.Partition)
[2024-09-06 20:05:51,638] INFO [Partition multi-broker-topic-topic-6 broker=0] Log loaded for partition multi-broker-topic-topic-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,639] INFO [Partition multi-broker-topic-topic-6 broker=2] No checkpointed highwatermark is found for partition multi-broker-topic-topic-6 (kafka.cluster.Partition)
[2024-09-06 20:05:51,639] INFO [Partition multi-broker-topic-topic-6 broker=2] Log loaded for partition multi-broker-topic-topic-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,641] INFO Created log for partition multi-broker-topic-topic-4 in D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-topic-4 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,645] INFO [Partition multi-broker-topic-topic-4 broker=1] No checkpointed highwatermark is found for partition multi-broker-topic-topic-4 (kafka.cluster.Partition)
[2024-09-06 20:05:51,645] INFO [Partition multi-broker-topic-topic-4 broker=1] Log loaded for partition multi-broker-topic-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,653] INFO [LogLoader partition=multi-broker-topic-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,653] INFO Created log for partition multi-broker-topic-topic-4 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-4 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,654] INFO [Partition multi-broker-topic-topic-4 broker=0] No checkpointed highwatermark is found for partition multi-broker-topic-topic-4 (kafka.cluster.Partition)
[2024-09-06 20:05:51,654] INFO [Partition multi-broker-topic-topic-4 broker=0] Log loaded for partition multi-broker-topic-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,667] INFO [LogLoader partition=multi-broker-topic-topic-3, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,668] INFO [LogLoader partition=multi-broker-topic-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,668] INFO Created log for partition multi-broker-topic-topic-3 in D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-topic-3 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,669] INFO [Partition multi-broker-topic-topic-3 broker=2] No checkpointed highwatermark is found for partition multi-broker-topic-topic-3 (kafka.cluster.Partition)
[2024-09-06 20:05:51,669] INFO [Partition multi-broker-topic-topic-3 broker=2] Log loaded for partition multi-broker-topic-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,669] INFO Created log for partition multi-broker-topic-topic-3 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-3 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,669] INFO [Partition multi-broker-topic-topic-3 broker=0] No checkpointed highwatermark is found for partition multi-broker-topic-topic-3 (kafka.cluster.Partition)
[2024-09-06 20:05:51,670] INFO [Partition multi-broker-topic-topic-3 broker=0] Log loaded for partition multi-broker-topic-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,676] INFO [LogLoader partition=multi-broker-topic-topic-1, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,677] INFO Created log for partition multi-broker-topic-topic-1 in D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-topic-1 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,678] INFO [Partition multi-broker-topic-topic-1 broker=1] No checkpointed highwatermark is found for partition multi-broker-topic-topic-1 (kafka.cluster.Partition)
[2024-09-06 20:05:51,678] INFO [Partition multi-broker-topic-topic-1 broker=1] Log loaded for partition multi-broker-topic-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,683] INFO [LogLoader partition=multi-broker-topic-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,684] INFO Created log for partition multi-broker-topic-topic-1 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-1 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,684] INFO [Partition multi-broker-topic-topic-1 broker=0] No checkpointed highwatermark is found for partition multi-broker-topic-topic-1 (kafka.cluster.Partition)
[2024-09-06 20:05:51,684] INFO [Partition multi-broker-topic-topic-1 broker=0] Log loaded for partition multi-broker-topic-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,686] INFO [LogLoader partition=multi-broker-topic-topic-0, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,687] INFO Created log for partition multi-broker-topic-topic-0 in D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-topic-0 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,688] INFO [Partition multi-broker-topic-topic-0 broker=2] No checkpointed highwatermark is found for partition multi-broker-topic-topic-0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,688] INFO [Partition multi-broker-topic-topic-0 broker=2] Log loaded for partition multi-broker-topic-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,698] INFO [LogLoader partition=multi-broker-topic-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,699] INFO [LogLoader partition=multi-broker-topic-topic-6, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,699] INFO Created log for partition multi-broker-topic-topic-0 in D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-0 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,699] INFO Created log for partition multi-broker-topic-topic-6 in D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-topic-6 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,700] INFO [Partition multi-broker-topic-topic-0 broker=0] No checkpointed highwatermark is found for partition multi-broker-topic-topic-0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,700] INFO [Partition multi-broker-topic-topic-6 broker=1] No checkpointed highwatermark is found for partition multi-broker-topic-topic-6 (kafka.cluster.Partition)
[2024-09-06 20:05:51,700] INFO [Partition multi-broker-topic-topic-0 broker=0] Log loaded for partition multi-broker-topic-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,700] INFO [Partition multi-broker-topic-topic-6 broker=1] Log loaded for partition multi-broker-topic-topic-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,701] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(multi-broker-topic-topic-0, multi-broker-topic-topic-1, multi-broker-topic-topic-3, multi-broker-topic-topic-4, multi-broker-topic-topic-6) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,706] INFO [LogLoader partition=multi-broker-topic-topic-5, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,707] INFO Created log for partition multi-broker-topic-topic-5 in D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-topic-5 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,707] INFO [Partition multi-broker-topic-topic-5 broker=2] No checkpointed highwatermark is found for partition multi-broker-topic-topic-5 (kafka.cluster.Partition)
[2024-09-06 20:05:51,708] INFO [Partition multi-broker-topic-topic-5 broker=2] Log loaded for partition multi-broker-topic-topic-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,714] INFO [LogLoader partition=multi-broker-topic-topic-5, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,716] INFO Created log for partition multi-broker-topic-topic-5 in D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-topic-5 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,716] INFO [Partition multi-broker-topic-topic-5 broker=1] No checkpointed highwatermark is found for partition multi-broker-topic-topic-5 (kafka.cluster.Partition)
[2024-09-06 20:05:51,716] INFO [Partition multi-broker-topic-topic-5 broker=1] Log loaded for partition multi-broker-topic-topic-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,721] INFO [LogLoader partition=multi-broker-topic-topic-4, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,722] INFO Created log for partition multi-broker-topic-topic-4 in D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-topic-4 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,722] INFO [Partition multi-broker-topic-topic-4 broker=2] No checkpointed highwatermark is found for partition multi-broker-topic-topic-4 (kafka.cluster.Partition)
[2024-09-06 20:05:51,722] INFO [Partition multi-broker-topic-topic-4 broker=2] Log loaded for partition multi-broker-topic-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,727] INFO [LogLoader partition=multi-broker-topic-topic-3, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,728] INFO Created log for partition multi-broker-topic-topic-3 in D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-topic-3 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,728] INFO [Partition multi-broker-topic-topic-3 broker=1] No checkpointed highwatermark is found for partition multi-broker-topic-topic-3 (kafka.cluster.Partition)
[2024-09-06 20:05:51,729] INFO [Partition multi-broker-topic-topic-3 broker=1] Log loaded for partition multi-broker-topic-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,729] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,733] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions HashMap(multi-broker-topic-topic-0 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),0,0), multi-broker-topic-topic-3 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),0,0), multi-broker-topic-topic-6 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,734] INFO [LogLoader partition=multi-broker-topic-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,735] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,735] INFO Created log for partition multi-broker-topic-topic-2 in D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-topic-2 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,735] INFO [Partition multi-broker-topic-topic-2 broker=2] No checkpointed highwatermark is found for partition multi-broker-topic-topic-2 (kafka.cluster.Partition)
[2024-09-06 20:05:51,736] INFO [Partition multi-broker-topic-topic-2 broker=2] Log loaded for partition multi-broker-topic-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,736] INFO [UnifiedLog partition=multi-broker-topic-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,738] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,738] INFO [UnifiedLog partition=multi-broker-topic-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,739] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,739] INFO [UnifiedLog partition=multi-broker-topic-topic-6, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,739] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions HashMap(multi-broker-topic-topic-4 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=1, host=localhost:9093),0,0), multi-broker-topic-topic-1 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=1, host=localhost:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,739] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,740] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition multi-broker-topic-topic-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,740] INFO [UnifiedLog partition=multi-broker-topic-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,740] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition multi-broker-topic-topic-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,741] INFO [UnifiedLog partition=multi-broker-topic-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,744] INFO [LogLoader partition=multi-broker-topic-topic-2, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,744] INFO Created log for partition multi-broker-topic-topic-2 in D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-topic-2 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,744] INFO [Partition multi-broker-topic-topic-2 broker=1] No checkpointed highwatermark is found for partition multi-broker-topic-topic-2 (kafka.cluster.Partition)
[2024-09-06 20:05:51,745] INFO [Partition multi-broker-topic-topic-2 broker=1] Log loaded for partition multi-broker-topic-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,751] INFO [LogLoader partition=multi-broker-topic-topic-1, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,752] INFO Created log for partition multi-broker-topic-topic-1 in D:\kafka\__manual-logs__\server2-logs\multi-broker-topic-topic-1 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,752] INFO [Partition multi-broker-topic-topic-1 broker=2] No checkpointed highwatermark is found for partition multi-broker-topic-topic-1 (kafka.cluster.Partition)
[2024-09-06 20:05:51,752] INFO [Partition multi-broker-topic-topic-1 broker=2] Log loaded for partition multi-broker-topic-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,753] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(multi-broker-topic-topic-1, multi-broker-topic-topic-2, multi-broker-topic-topic-4, multi-broker-topic-topic-5) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,761] INFO [LogLoader partition=multi-broker-topic-topic-0, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:05:51,762] INFO Created log for partition multi-broker-topic-topic-0 in D:\kafka\__manual-logs__\server1-logs\multi-broker-topic-topic-0 with properties {} (kafka.log.LogManager)
[2024-09-06 20:05:51,762] INFO [Partition multi-broker-topic-topic-0 broker=1] No checkpointed highwatermark is found for partition multi-broker-topic-topic-0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,762] INFO [Partition multi-broker-topic-topic-0 broker=1] Log loaded for partition multi-broker-topic-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:05:51,763] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(multi-broker-topic-topic-0, multi-broker-topic-topic-2, multi-broker-topic-topic-3, multi-broker-topic-topic-5, multi-broker-topic-topic-6) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,775] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition multi-broker-topic-topic-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,775] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition multi-broker-topic-topic-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,775] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition multi-broker-topic-topic-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,776] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition multi-broker-topic-topic-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,776] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition multi-broker-topic-topic-6. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,812] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,815] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,816] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(multi-broker-topic-topic-2 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=0, host=localhost:9092),0,0), multi-broker-topic-topic-5 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=0, host=localhost:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,816] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition multi-broker-topic-topic-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,818] INFO [UnifiedLog partition=multi-broker-topic-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,819] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions HashMap(multi-broker-topic-topic-5 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=0, host=localhost:9092),0,0), multi-broker-topic-topic-2 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=0, host=localhost:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,820] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition multi-broker-topic-topic-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,821] INFO [UnifiedLog partition=multi-broker-topic-topic-5, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,820] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition multi-broker-topic-topic-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,822] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(multi-broker-topic-topic-4 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=1, host=localhost:9093),0,0), multi-broker-topic-topic-1 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=1, host=localhost:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,822] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,823] INFO [UnifiedLog partition=multi-broker-topic-topic-2, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,823] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition multi-broker-topic-topic-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,824] INFO [UnifiedLog partition=multi-broker-topic-topic-1, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,824] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition multi-broker-topic-topic-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,824] INFO [UnifiedLog partition=multi-broker-topic-topic-4, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,825] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition multi-broker-topic-topic-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,826] INFO [UnifiedLog partition=multi-broker-topic-topic-5, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,827] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions HashMap(multi-broker-topic-topic-0 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),0,0), multi-broker-topic-topic-3 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),0,0), multi-broker-topic-topic-6 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:05:51,827] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,828] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,828] INFO [UnifiedLog partition=multi-broker-topic-topic-0, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,828] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,829] INFO [UnifiedLog partition=multi-broker-topic-topic-3, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,829] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,829] INFO [UnifiedLog partition=multi-broker-topic-topic-6, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:05:51,842] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition multi-broker-topic-topic-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:05:51,842] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition multi-broker-topic-topic-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,103] INFO Creating topic multi-replica-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0, 2, 1), 1 -> ArrayBuffer(2, 1, 0), 2 -> ArrayBuffer(1, 0, 2), 3 -> ArrayBuffer(0, 1, 2), 4 -> ArrayBuffer(2, 0, 1), 5 -> ArrayBuffer(1, 2, 0), 6 -> ArrayBuffer(0, 2, 1)) (kafka.zk.AdminZkClient)
[2024-09-06 20:10:10,134] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(multi-replica-topic-0, multi-replica-topic-3, multi-replica-topic-6) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,136] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(multi-replica-topic-2, multi-replica-topic-5) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,137] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(multi-replica-topic-1, multi-replica-topic-4) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,150] INFO [LogLoader partition=multi-replica-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,152] INFO Created log for partition multi-replica-topic-0 in D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-0 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,152] INFO [LogLoader partition=multi-replica-topic-1, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,154] INFO [LogLoader partition=multi-replica-topic-2, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,154] INFO Created log for partition multi-replica-topic-1 in D:\kafka\__manual-logs__\server2-logs\multi-replica-topic-1 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,154] INFO Created log for partition multi-replica-topic-2 in D:\kafka\__manual-logs__\server1-logs\multi-replica-topic-2 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,155] INFO [Partition multi-replica-topic-1 broker=2] No checkpointed highwatermark is found for partition multi-replica-topic-1 (kafka.cluster.Partition)
[2024-09-06 20:10:10,156] INFO [Partition multi-replica-topic-1 broker=2] Log loaded for partition multi-replica-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,157] INFO [Partition multi-replica-topic-0 broker=0] No checkpointed highwatermark is found for partition multi-replica-topic-0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,158] INFO [Partition multi-replica-topic-0 broker=0] Log loaded for partition multi-replica-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,158] INFO [Partition multi-replica-topic-2 broker=1] No checkpointed highwatermark is found for partition multi-replica-topic-2 (kafka.cluster.Partition)
[2024-09-06 20:10:10,158] INFO [Partition multi-replica-topic-2 broker=1] Log loaded for partition multi-replica-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,175] INFO [LogLoader partition=multi-replica-topic-5, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,175] INFO [LogLoader partition=multi-replica-topic-4, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,176] INFO [LogLoader partition=multi-replica-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,176] INFO Created log for partition multi-replica-topic-4 in D:\kafka\__manual-logs__\server2-logs\multi-replica-topic-4 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,176] INFO Created log for partition multi-replica-topic-5 in D:\kafka\__manual-logs__\server1-logs\multi-replica-topic-5 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,177] INFO Created log for partition multi-replica-topic-3 in D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-3 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,176] INFO [Partition multi-replica-topic-4 broker=2] No checkpointed highwatermark is found for partition multi-replica-topic-4 (kafka.cluster.Partition)
[2024-09-06 20:10:10,176] INFO [Partition multi-replica-topic-5 broker=1] No checkpointed highwatermark is found for partition multi-replica-topic-5 (kafka.cluster.Partition)
[2024-09-06 20:10:10,178] INFO [Partition multi-replica-topic-4 broker=2] Log loaded for partition multi-replica-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,178] INFO [Partition multi-replica-topic-5 broker=1] Log loaded for partition multi-replica-topic-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,178] INFO [Partition multi-replica-topic-3 broker=0] No checkpointed highwatermark is found for partition multi-replica-topic-3 (kafka.cluster.Partition)
[2024-09-06 20:10:10,179] INFO [Partition multi-replica-topic-3 broker=0] Log loaded for partition multi-replica-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,196] INFO [LogLoader partition=multi-replica-topic-0, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,196] INFO [LogLoader partition=multi-replica-topic-0, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,196] INFO Created log for partition multi-replica-topic-0 in D:\kafka\__manual-logs__\server1-logs\multi-replica-topic-0 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,197] INFO [Partition multi-replica-topic-0 broker=1] No checkpointed highwatermark is found for partition multi-replica-topic-0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,197] INFO [Partition multi-replica-topic-0 broker=1] Log loaded for partition multi-replica-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,197] INFO Created log for partition multi-replica-topic-0 in D:\kafka\__manual-logs__\server2-logs\multi-replica-topic-0 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,197] INFO [LogLoader partition=multi-replica-topic-6, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,198] INFO Created log for partition multi-replica-topic-6 in D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-6 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,198] INFO [Partition multi-replica-topic-6 broker=0] No checkpointed highwatermark is found for partition multi-replica-topic-6 (kafka.cluster.Partition)
[2024-09-06 20:10:10,197] INFO [Partition multi-replica-topic-0 broker=2] No checkpointed highwatermark is found for partition multi-replica-topic-0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,198] INFO [Partition multi-replica-topic-6 broker=0] Log loaded for partition multi-replica-topic-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,198] INFO [Partition multi-replica-topic-0 broker=2] Log loaded for partition multi-replica-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,209] INFO [LogLoader partition=multi-replica-topic-1, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,210] INFO Created log for partition multi-replica-topic-1 in D:\kafka\__manual-logs__\server1-logs\multi-replica-topic-1 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,210] INFO [Partition multi-replica-topic-1 broker=1] No checkpointed highwatermark is found for partition multi-replica-topic-1 (kafka.cluster.Partition)
[2024-09-06 20:10:10,210] INFO [Partition multi-replica-topic-1 broker=1] Log loaded for partition multi-replica-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,211] INFO [LogLoader partition=multi-replica-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,212] INFO Created log for partition multi-replica-topic-2 in D:\kafka\__manual-logs__\server2-logs\multi-replica-topic-2 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,212] INFO [Partition multi-replica-topic-2 broker=2] No checkpointed highwatermark is found for partition multi-replica-topic-2 (kafka.cluster.Partition)
[2024-09-06 20:10:10,212] INFO [Partition multi-replica-topic-2 broker=2] Log loaded for partition multi-replica-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,215] INFO [LogLoader partition=multi-replica-topic-2, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,216] INFO Created log for partition multi-replica-topic-2 in D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-2 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,216] INFO [Partition multi-replica-topic-2 broker=0] No checkpointed highwatermark is found for partition multi-replica-topic-2 (kafka.cluster.Partition)
[2024-09-06 20:10:10,216] INFO [Partition multi-replica-topic-2 broker=0] Log loaded for partition multi-replica-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,223] INFO [LogLoader partition=multi-replica-topic-4, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,224] INFO Created log for partition multi-replica-topic-4 in D:\kafka\__manual-logs__\server1-logs\multi-replica-topic-4 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,224] INFO [Partition multi-replica-topic-4 broker=1] No checkpointed highwatermark is found for partition multi-replica-topic-4 (kafka.cluster.Partition)
[2024-09-06 20:10:10,225] INFO [Partition multi-replica-topic-4 broker=1] Log loaded for partition multi-replica-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,225] INFO [LogLoader partition=multi-replica-topic-3, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,226] INFO Created log for partition multi-replica-topic-3 in D:\kafka\__manual-logs__\server2-logs\multi-replica-topic-3 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,226] INFO [Partition multi-replica-topic-3 broker=2] No checkpointed highwatermark is found for partition multi-replica-topic-3 (kafka.cluster.Partition)
[2024-09-06 20:10:10,226] INFO [Partition multi-replica-topic-3 broker=2] Log loaded for partition multi-replica-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,230] INFO [LogLoader partition=multi-replica-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,231] INFO Created log for partition multi-replica-topic-1 in D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-1 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,231] INFO [Partition multi-replica-topic-1 broker=0] No checkpointed highwatermark is found for partition multi-replica-topic-1 (kafka.cluster.Partition)
[2024-09-06 20:10:10,232] INFO [Partition multi-replica-topic-1 broker=0] Log loaded for partition multi-replica-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,238] INFO [LogLoader partition=multi-replica-topic-3, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,239] INFO Created log for partition multi-replica-topic-3 in D:\kafka\__manual-logs__\server1-logs\multi-replica-topic-3 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,239] INFO [LogLoader partition=multi-replica-topic-6, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,239] INFO [Partition multi-replica-topic-3 broker=1] No checkpointed highwatermark is found for partition multi-replica-topic-3 (kafka.cluster.Partition)
[2024-09-06 20:10:10,239] INFO [Partition multi-replica-topic-3 broker=1] Log loaded for partition multi-replica-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,240] INFO Created log for partition multi-replica-topic-6 in D:\kafka\__manual-logs__\server2-logs\multi-replica-topic-6 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,240] INFO [Partition multi-replica-topic-6 broker=2] No checkpointed highwatermark is found for partition multi-replica-topic-6 (kafka.cluster.Partition)
[2024-09-06 20:10:10,241] INFO [Partition multi-replica-topic-6 broker=2] Log loaded for partition multi-replica-topic-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,245] INFO [LogLoader partition=multi-replica-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,245] INFO Created log for partition multi-replica-topic-4 in D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-4 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,246] INFO [Partition multi-replica-topic-4 broker=0] No checkpointed highwatermark is found for partition multi-replica-topic-4 (kafka.cluster.Partition)
[2024-09-06 20:10:10,246] INFO [Partition multi-replica-topic-4 broker=0] Log loaded for partition multi-replica-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,253] INFO [LogLoader partition=multi-replica-topic-5, dir=D:\kafka\__manual-logs__\server2-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,253] INFO [LogLoader partition=multi-replica-topic-6, dir=D:\kafka\__manual-logs__\server1-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,255] INFO Created log for partition multi-replica-topic-6 in D:\kafka\__manual-logs__\server1-logs\multi-replica-topic-6 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,255] INFO [Partition multi-replica-topic-6 broker=1] No checkpointed highwatermark is found for partition multi-replica-topic-6 (kafka.cluster.Partition)
[2024-09-06 20:10:10,255] INFO Created log for partition multi-replica-topic-5 in D:\kafka\__manual-logs__\server2-logs\multi-replica-topic-5 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,255] INFO [Partition multi-replica-topic-6 broker=1] Log loaded for partition multi-replica-topic-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,255] INFO [Partition multi-replica-topic-5 broker=2] No checkpointed highwatermark is found for partition multi-replica-topic-5 (kafka.cluster.Partition)
[2024-09-06 20:10:10,256] INFO [Partition multi-replica-topic-5 broker=2] Log loaded for partition multi-replica-topic-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,256] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(multi-replica-topic-6, multi-replica-topic-4, multi-replica-topic-3, multi-replica-topic-0, multi-replica-topic-1) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,257] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(multi-replica-topic-6, multi-replica-topic-5, multi-replica-topic-2, multi-replica-topic-3, multi-replica-topic-0) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,258] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions HashMap(multi-replica-topic-0 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),0,0), multi-replica-topic-3 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),0,0), multi-replica-topic-6 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,258] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions HashMap(multi-replica-topic-4 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),0,0), multi-replica-topic-1 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,260] INFO [LogLoader partition=multi-replica-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 20:10:10,260] INFO Created log for partition multi-replica-topic-5 in D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-5 with properties {} (kafka.log.LogManager)
[2024-09-06 20:10:10,261] INFO [Partition multi-replica-topic-5 broker=0] No checkpointed highwatermark is found for partition multi-replica-topic-5 (kafka.cluster.Partition)
[2024-09-06 20:10:10,261] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions HashMap(multi-replica-topic-0 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),0,0), multi-replica-topic-3 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),0,0), multi-replica-topic-6 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,261] INFO [Partition multi-replica-topic-5 broker=0] Log loaded for partition multi-replica-topic-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 20:10:10,261] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions HashMap(multi-replica-topic-2 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=1, host=localhost:9093),0,0), multi-replica-topic-5 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=1, host=localhost:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,262] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(multi-replica-topic-4, multi-replica-topic-5, multi-replica-topic-2, multi-replica-topic-1) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,264] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(multi-replica-topic-4 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),0,0), multi-replica-topic-1 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,264] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(multi-replica-topic-5 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=1, host=localhost:9093),0,0), multi-replica-topic-2 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=1, host=localhost:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:10:10,347] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition multi-replica-topic-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,347] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition multi-replica-topic-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,347] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition multi-replica-topic-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,347] INFO [UnifiedLog partition=multi-replica-topic-6, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,349] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition multi-replica-topic-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,347] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition multi-replica-topic-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,347] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition multi-replica-topic-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,347] INFO [UnifiedLog partition=multi-replica-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,352] INFO [UnifiedLog partition=multi-replica-topic-3, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,347] INFO [UnifiedLog partition=multi-replica-topic-6, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,352] INFO [UnifiedLog partition=multi-replica-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,353] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition multi-replica-topic-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,353] INFO [UnifiedLog partition=multi-replica-topic-4, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,353] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition multi-replica-topic-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,355] INFO [UnifiedLog partition=multi-replica-topic-0, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,354] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition multi-replica-topic-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,355] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition multi-replica-topic-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,355] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition multi-replica-topic-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,356] INFO [UnifiedLog partition=multi-replica-topic-2, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,357] INFO [UnifiedLog partition=multi-replica-topic-3, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,357] INFO [UnifiedLog partition=multi-replica-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,358] INFO [UnifiedLog partition=multi-replica-topic-1, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,358] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition multi-replica-topic-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,359] INFO [UnifiedLog partition=multi-replica-topic-0, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,752] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition multi-replica-topic-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,753] INFO [UnifiedLog partition=multi-replica-topic-5, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:10:10,754] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition multi-replica-topic-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:10:10,754] INFO [UnifiedLog partition=multi-replica-topic-2, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:17:20,399] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-96964 in state PreparingRebalance with old generation 1 (__consumer_offsets-15) (reason: Removing member console-consumer-40f12e9a-e3ab-491b-8602-b1d8f8a145f4 on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:17:20,399] INFO [GroupCoordinator 0]: Group console-consumer-96964 with generation 2 is now empty (__consumer_offsets-15) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:17:20,402] INFO [GroupCoordinator 0]: Member MemberMetadata(memberId=console-consumer-40f12e9a-e3ab-491b-8602-b1d8f8a145f4, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-96964 through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:18:18,865] INFO [GroupMetadataManager brokerId=0] Group console-consumer-96964 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 20:18:27,489] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group console-consumer-79125 in Empty state. Created a new member id console-consumer-f6dbf2f3-848b-43ec-91b4-6c4ea5f9f689 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:18:27,506] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-79125 in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member console-consumer-f6dbf2f3-848b-43ec-91b4-6c4ea5f9f689 with group instance id None; client reason: need to re-join with the given member-id: console-consumer-f6dbf2f3-848b-43ec-91b4-6c4ea5f9f689) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:18:27,524] INFO [GroupCoordinator 1]: Stabilized group console-consumer-79125 generation 1 (__consumer_offsets-35) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:18:27,551] INFO [GroupCoordinator 1]: Assignment received from leader console-consumer-f6dbf2f3-848b-43ec-91b4-6c4ea5f9f689 for group console-consumer-79125 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:30:18,288] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-79125 in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: Removing member console-consumer-f6dbf2f3-848b-43ec-91b4-6c4ea5f9f689 on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:30:18,293] INFO [GroupCoordinator 1]: Group console-consumer-79125 with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:30:18,296] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=console-consumer-f6dbf2f3-848b-43ec-91b4-6c4ea5f9f689, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-79125 through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:30:29,978] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group console-consumer-90224 in Empty state. Created a new member id console-consumer-4ca4fa6a-ea90-4a41-b9d1-cc37dbfea408 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:30:29,981] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-90224 in state PreparingRebalance with old generation 0 (__consumer_offsets-18) (reason: Adding new member console-consumer-4ca4fa6a-ea90-4a41-b9d1-cc37dbfea408 with group instance id None; client reason: need to re-join with the given member-id: console-consumer-4ca4fa6a-ea90-4a41-b9d1-cc37dbfea408) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:30:29,982] INFO [GroupCoordinator 0]: Stabilized group console-consumer-90224 generation 1 (__consumer_offsets-18) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:30:29,996] INFO [GroupCoordinator 0]: Assignment received from leader console-consumer-4ca4fa6a-ea90-4a41-b9d1-cc37dbfea408 for group console-consumer-90224 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:38:27,164] INFO [GroupMetadataManager brokerId=1] Group console-consumer-79125 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 20:55:09,900] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-09-06 20:55:09,910] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2024-09-06 20:55:09,982] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:09,982] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:09,982] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:09,985] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(multi-replica-topic-6, multi-replica-topic-3, multi-replica-topic-0, multi-broker-topic-topic-2, multi-broker-topic-topic-5) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:09,988] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(multi-replica-topic-0, multi-broker-topic-topic-2, multi-replica-topic-6) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:09,993] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(multi-broker-topic-topic-5, multi-replica-topic-3) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,002] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Partition multi-broker-topic-topic-2 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,004] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Partition multi-broker-topic-topic-2 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,004] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Partition multi-replica-topic-6 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,005] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Partition multi-broker-topic-topic-5 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,005] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Partition multi-replica-topic-6 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,006] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Partition multi-broker-topic-topic-5 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,006] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Partition multi-replica-topic-0 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,006] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 69ms (kafka.server.KafkaServer)
[2024-09-06 20:55:10,007] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Partition multi-replica-topic-3 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,009] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Partition multi-replica-topic-0 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,010] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Partition multi-replica-topic-3 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,010] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(multi-replica-topic-6, multi-replica-topic-0, multi-broker-topic-topic-2) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,012] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 20:55:10,013] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 20:55:10,013] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 20:55:10,013] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(multi-replica-topic-3, multi-broker-topic-topic-5) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,013] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(multi-replica-topic-6 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),1,3), multi-replica-topic-0 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),1,2), multi-broker-topic-topic-2 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),1,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,015] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-09-06 20:55:10,015] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,016] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(multi-broker-topic-topic-5 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=1, host=localhost:9093),1,0), multi-replica-topic-3 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=1, host=localhost:9093),1,1)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,017] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,017] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,018] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,020] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,020] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,022] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,024] INFO [Controller id=0, targetBrokerId=0] Cancelled in-flight STOP_REPLICA request with correlation id 13 due to node 0 being disconnected (elapsed time since creation: 11ms, elapsed time since send: 11ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,024] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(multi-replica-topic-4, multi-broker-topic-topic-0, multi-broker-topic-topic-4, multi-replica-topic-2, multi-broker-topic-topic-3, multi-broker-topic-topic-6, multi-replica-topic-5, multi-broker-topic-topic-1, multi-replica-topic-1) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,027] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-09-06 20:55:10,028] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions HashSet(multi-replica-topic-4, multi-broker-topic-topic-0, multi-broker-topic-topic-4, multi-replica-topic-2, multi-broker-topic-topic-3, multi-broker-topic-topic-6, multi-replica-topic-5, multi-broker-topic-topic-1, multi-replica-topic-1) (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 20:55:10,029] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 20:55:10,029] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,034] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(multi-broker-topic-topic-4, multi-broker-topic-topic-1, multi-replica-topic-2, multi-replica-topic-5) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,037] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(multi-replica-topic-4, multi-broker-topic-topic-0, multi-broker-topic-topic-3, multi-broker-topic-topic-6, multi-replica-topic-1) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,039] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,041] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,042] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5792 due to node 2 being disconnected (elapsed time since creation: 142ms, elapsed time since send: 142ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,043] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1710002869, epoch=5790) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:135)
[2024-09-06 20:55:10,043] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,043] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,046] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,046] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,047] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5791 due to node 1 being disconnected (elapsed time since creation: 441ms, elapsed time since send: 441ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,047] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=159941506, epoch=5789) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:135)
[2024-09-06 20:55:10,048] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,048] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,050] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2024-09-06 20:55:10,054] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(multi-replica-topic-4, multi-broker-topic-topic-0, multi-replica-topic-1, multi-broker-topic-topic-3, multi-broker-topic-topic-6) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,053] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,055] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions HashMap(multi-replica-topic-4 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),1,2), multi-broker-topic-topic-0 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),1,0), multi-broker-topic-topic-3 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),1,0), multi-broker-topic-topic-6 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),1,0), multi-replica-topic-1 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),1,5)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,057] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,057] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,060] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2024-09-06 20:55:10,061] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,062] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,062] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,062] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(multi-replica-topic-5, multi-replica-topic-2, multi-broker-topic-topic-1, multi-broker-topic-topic-4) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,063] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(multi-broker-topic-topic-4 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=1, host=localhost:9093),1,0), multi-replica-topic-2 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=1, host=localhost:9093),1,4), multi-replica-topic-5 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=1, host=localhost:9093),1,3), multi-broker-topic-topic-1 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=1, host=localhost:9093),1,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,064] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 20:55:10,066] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2024-09-06 20:55:10,067] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 20:55:10,069] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 20:55:10,069] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 20:55:10,072] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 20:55:10,072] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:55:10,073] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,073] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,073] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,075] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,076] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,076] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,078] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 20:55:10,079] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-09-06 20:55:10,079] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 20:55:10,080] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 20:55:10,080] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 20:55:10,081] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,082] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-09-06 20:55:10,085] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 20:55:10,085] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-09-06 20:55:10,086] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,086] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,086] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,087] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,088] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,088] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,089] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,091] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,091] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,091] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,092] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,092] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,093] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,093] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,094] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 20:55:10,100] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 20:55:10,100] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 20:55:10,100] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 20:55:10,103] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-09-06 20:55:10,103] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 20:55:10,104] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 20:55:10,104] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 20:55:10,105] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 20:55:10,106] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-09-06 20:55:10,106] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-09-06 20:55:10,106] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-09-06 20:55:10,107] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-09-06 20:55:10,108] INFO Shutting down. (kafka.log.LogManager)
[2024-09-06 20:55:10,111] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 20:55:10,111] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 20:55:10,111] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 20:55:10,144] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,145] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,147] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,176] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Partition multi-replica-topic-2 has a newer epoch (1) than the current leader. Retry the partition later. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,177] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Partition multi-replica-topic-5 has a newer epoch (1) than the current leader. Retry the partition later. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,177] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition multi-broker-topic-topic-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,177] INFO [UnifiedLog partition=multi-broker-topic-topic-1, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:55:10,177] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition multi-broker-topic-topic-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,178] INFO [UnifiedLog partition=multi-broker-topic-topic-4, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:55:10,178] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition multi-broker-topic-topic-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,178] INFO [UnifiedLog partition=multi-broker-topic-topic-5, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:55:10,245] INFO [ProducerStateManager partition=multi-replica-topic-6] Wrote producer snapshot at offset 3 with 1 producer ids in 5 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:10,252] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,252] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,253] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,333] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Partition multi-replica-topic-4 has a newer epoch (1) than the current leader. Retry the partition later. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,334] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Partition multi-replica-topic-1 has a newer epoch (1) than the current leader. Retry the partition later. (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,335] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,336] INFO [UnifiedLog partition=multi-broker-topic-topic-0, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:55:10,336] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,336] INFO [UnifiedLog partition=multi-broker-topic-topic-2, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:55:10,336] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,336] INFO [UnifiedLog partition=multi-broker-topic-topic-3, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:55:10,336] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 20:55:10,337] INFO [UnifiedLog partition=multi-broker-topic-topic-6, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 20:55:10,355] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,355] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,359] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,391] INFO [ProducerStateManager partition=multi-replica-topic-4] Wrote producer snapshot at offset 2 with 1 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:10,463] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,463] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,465] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,527] INFO [ProducerStateManager partition=multi-broker-topic-4] Wrote producer snapshot at offset 2 with 1 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:10,571] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,571] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,576] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,651] INFO [ProducerStateManager partition=multi-replica-topic-3] Wrote producer snapshot at offset 1 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:10,680] INFO [ProducerStateManager partition=__consumer_offsets-18] Wrote producer snapshot at offset 4 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:10,692] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,693] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,694] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,784] INFO [ProducerStateManager partition=multi-broker-topic-5] Wrote producer snapshot at offset 2 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:10,802] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,802] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,803] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,815] INFO [ProducerStateManager partition=multi-broker-topic-1] Wrote producer snapshot at offset 3 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:10,846] INFO [ProducerStateManager partition=multi-replica-topic-2] Wrote producer snapshot at offset 4 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:10,877] INFO [ProducerStateManager partition=multi-replica-topic-0] Wrote producer snapshot at offset 2 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:10,908] INFO [ProducerStateManager partition=multi-replica-topic-5] Wrote producer snapshot at offset 3 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:10,909] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,910] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:10,913] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:11,019] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:11,019] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:11,022] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:11,041] INFO [ProducerStateManager partition=__consumer_offsets-15] Wrote producer snapshot at offset 3 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:11,103] INFO [ProducerStateManager partition=multi-replica-topic-1] Wrote producer snapshot at offset 5 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 20:55:11,127] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:11,127] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:11,127] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:11,200] INFO Shutdown complete. (kafka.log.LogManager)
[2024-09-06 20:55:11,203] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 20:55:11,208] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 20:55:11,209] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 20:55:11,209] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 20:55:11,210] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 20:55:11,329] INFO Session: 0x100396b1a210006 closed (org.apache.zookeeper.ZooKeeper)
[2024-09-06 20:55:11,329] INFO EventThread shut down for session: 0x100396b1a210006 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 20:55:11,330] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 20:55:11,334] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,336] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,336] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,337] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,338] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,338] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,338] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,339] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,339] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,340] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,342] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,342] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 20:55:11,344] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-09-06 20:55:11,367] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-09-06 20:55:11,367] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 20:55:11,367] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 20:55:11,371] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-09-06 20:55:11,372] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-09-06 20:55:11,374] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 20:55:11,374] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-09-06 21:26:23,648] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-09-06 21:26:23,955] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-09-06 21:26:23,958] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 21:26:24,095] INFO starting (kafka.server.KafkaServer)
[2024-09-06 21:26:24,095] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-09-06 21:26:24,111] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 21:26:24,116] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,117] INFO Client environment:host.name=AASPL176.alignedautomation.com (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,117] INFO Client environment:java.version=19.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,120] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,120] INFO Client environment:java.home=C:\Program Files\Java\jdk-19 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,121] INFO Client environment:java.class.path=D:\kafka\libs\activation-1.1.1.jar;D:\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\kafka\libs\argparse4j-0.7.0.jar;D:\kafka\libs\audience-annotations-0.12.0.jar;D:\kafka\libs\caffeine-2.9.3.jar;D:\kafka\libs\checker-qual-3.19.0.jar;D:\kafka\libs\commons-beanutils-1.9.4.jar;D:\kafka\libs\commons-cli-1.4.jar;D:\kafka\libs\commons-collections-3.2.2.jar;D:\kafka\libs\commons-digester-2.1.jar;D:\kafka\libs\commons-io-2.11.0.jar;D:\kafka\libs\commons-lang3-3.12.0.jar;D:\kafka\libs\commons-logging-1.2.jar;D:\kafka\libs\commons-validator-1.7.jar;D:\kafka\libs\connect-api-3.8.0.jar;D:\kafka\libs\connect-basic-auth-extension-3.8.0.jar;D:\kafka\libs\connect-file-3.8.0.jar;D:\kafka\libs\connect-json-3.8.0.jar;D:\kafka\libs\connect-mirror-3.8.0.jar;D:\kafka\libs\connect-mirror-client-3.8.0.jar;D:\kafka\libs\connect-runtime-3.8.0.jar;D:\kafka\libs\connect-transforms-3.8.0.jar;D:\kafka\libs\error_prone_annotations-2.10.0.jar;D:\kafka\libs\hk2-api-2.6.1.jar;D:\kafka\libs\hk2-locator-2.6.1.jar;D:\kafka\libs\hk2-utils-2.6.1.jar;D:\kafka\libs\jackson-annotations-2.16.2.jar;D:\kafka\libs\jackson-core-2.16.2.jar;D:\kafka\libs\jackson-databind-2.16.2.jar;D:\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\kafka\libs\jakarta.inject-2.6.1.jar;D:\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\kafka\libs\javassist-3.29.2-GA.jar;D:\kafka\libs\javax.activation-api-1.2.0.jar;D:\kafka\libs\javax.annotation-api-1.3.2.jar;D:\kafka\libs\javax.servlet-api-3.1.0.jar;D:\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\kafka\libs\jaxb-api-2.3.1.jar;D:\kafka\libs\jersey-client-2.39.1.jar;D:\kafka\libs\jersey-common-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\kafka\libs\jersey-hk2-2.39.1.jar;D:\kafka\libs\jersey-server-2.39.1.jar;D:\kafka\libs\jetty-client-9.4.54.v20240208.jar;D:\kafka\libs\jetty-continuation-9.4.54.v20240208.jar;D:\kafka\libs\jetty-http-9.4.54.v20240208.jar;D:\kafka\libs\jetty-io-9.4.54.v20240208.jar;D:\kafka\libs\jetty-security-9.4.54.v20240208.jar;D:\kafka\libs\jetty-server-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlet-9.4.54.v20240208.jar;D:\kafka\libs\jetty-servlets-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-9.4.54.v20240208.jar;D:\kafka\libs\jetty-util-ajax-9.4.54.v20240208.jar;D:\kafka\libs\jline-3.25.1.jar;D:\kafka\libs\jopt-simple-5.0.4.jar;D:\kafka\libs\jose4j-0.9.4.jar;D:\kafka\libs\jsr305-3.0.2.jar;D:\kafka\libs\kafka-clients-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-3.8.0.jar;D:\kafka\libs\kafka-group-coordinator-api-3.8.0.jar;D:\kafka\libs\kafka-log4j-appender-3.8.0.jar;D:\kafka\libs\kafka-metadata-3.8.0.jar;D:\kafka\libs\kafka-raft-3.8.0.jar;D:\kafka\libs\kafka-server-3.8.0.jar;D:\kafka\libs\kafka-server-common-3.8.0.jar;D:\kafka\libs\kafka-shell-3.8.0.jar;D:\kafka\libs\kafka-storage-3.8.0.jar;D:\kafka\libs\kafka-storage-api-3.8.0.jar;D:\kafka\libs\kafka-streams-3.8.0.jar;D:\kafka\libs\kafka-streams-examples-3.8.0.jar;D:\kafka\libs\kafka-streams-scala_2.13-3.8.0.jar;D:\kafka\libs\kafka-streams-test-utils-3.8.0.jar;D:\kafka\libs\kafka-tools-3.8.0.jar;D:\kafka\libs\kafka-tools-api-3.8.0.jar;D:\kafka\libs\kafka-transaction-coordinator-3.8.0.jar;D:\kafka\libs\kafka_2.13-3.8.0.jar;D:\kafka\libs\lz4-java-1.8.0.jar;D:\kafka\libs\maven-artifact-3.9.6.jar;D:\kafka\libs\metrics-core-2.2.0.jar;D:\kafka\libs\metrics-core-4.1.12.1.jar;D:\kafka\libs\netty-buffer-4.1.110.Final.jar;D:\kafka\libs\netty-codec-4.1.110.Final.jar;D:\kafka\libs\netty-common-4.1.110.Final.jar;D:\kafka\libs\netty-handler-4.1.110.Final.jar;D:\kafka\libs\netty-resolver-4.1.110.Final.jar;D:\kafka\libs\netty-transport-4.1.110.Final.jar;D:\kafka\libs\netty-transport-classes-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-epoll-4.1.110.Final.jar;D:\kafka\libs\netty-transport-native-unix-common-4.1.110.Final.jar;D:\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\kafka\libs\paranamer-2.8.jar;D:\kafka\libs\pcollections-4.0.1.jar;D:\kafka\libs\plexus-utils-3.5.1.jar;D:\kafka\libs\protobuf-java-3.23.4.jar;D:\kafka\libs\reflections-0.10.2.jar;D:\kafka\libs\reload4j-1.2.25.jar;D:\kafka\libs\rocksdbjni-7.9.2.jar;D:\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\kafka\libs\scala-library-2.13.14.jar;D:\kafka\libs\scala-logging_2.13-3.9.4.jar;D:\kafka\libs\scala-reflect-2.13.14.jar;D:\kafka\libs\slf4j-api-1.7.36.jar;D:\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\kafka\libs\snappy-java-1.1.10.5.jar;D:\kafka\libs\swagger-annotations-2.2.8.jar;D:\kafka\libs\trogdor-3.8.0.jar;D:\kafka\libs\zookeeper-3.8.4.jar;D:\kafka\libs\zookeeper-jute-3.8.4.jar;D:\kafka\libs\zstd-jni-1.5.6-3.jar (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,122] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-19\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\app\Jerin.sam\product\21c\dbhomeXE\bin;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\110\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\130\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Java\jdk-19\bin\;C:\Program Files\Java\jdk-19\\bin;D:\Kafka\hadoop\bin;D:\Kafka\spark-3.3.2-bin-hadoop3\bin;C:\Program Files\Microsoft\Azure Functions Core Tools\;C:\Users\jerin\AppData\Local\Programs\Python\Python38;C:\Users\jerin\AppData\Local\Programs\Python\Python38\Scripts\;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;D:\kafka\bin\windows;C:\Program Files\RSA SecurID Token Common\;C:\Users\jerin\AppData\Local\Programs\Microsoft VS Code\bin;;. (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,122] INFO Client environment:java.io.tmpdir=C:\Users\jerin\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,122] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,123] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,123] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,124] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,125] INFO Client environment:user.name=Jerin.sam (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,125] INFO Client environment:user.home=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,126] INFO Client environment:user.dir=C:\Users\jerin (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,126] INFO Client environment:os.memory.free=982MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,126] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,127] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,130] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@11f0a5a1 (org.apache.zookeeper.ZooKeeper)
[2024-09-06 21:26:24,176] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-09-06 21:26:24,185] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-09-06 21:26:24,187] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 21:26:24,188] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-09-06 21:26:24,192] INFO Socket connection established, initiating session, client: /127.0.0.1:49973, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 21:26:24,219] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100396b1a210009, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-09-06 21:26:24,224] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-09-06 21:26:24,478] INFO Cluster ID = ZaDmectTQz2HlvxxSWBbpA (kafka.server.KafkaServer)
[2024-09-06 21:26:24,487] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 21:26:24,522] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 21:26:24,528] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:\kafka\__manual-logs__\server0-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-09-06 21:26:24,531] INFO RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
 (org.apache.kafka.server.log.remote.storage.RemoteLogManagerConfig)
[2024-09-06 21:26:24,564] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 21:26:24,565] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 21:26:24,569] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 21:26:24,569] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-09-06 21:26:24,632] INFO Loading logs from log dirs ArrayBuffer(D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:24,650] INFO Skipping recovery of 36 logs from D:\kafka\__manual-logs__\server0-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-09-06 21:26:24,745] INFO [LogLoader partition=multi-broker-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,747] INFO [LogLoader partition=multi-broker-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,747] INFO [ProducerStateManager partition=multi-broker-topic-1] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-1\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:24,763] INFO [LogLoader partition=multi-broker-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 16ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,782] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-1, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 125ms (1/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:24,808] INFO [LogLoader partition=multi-broker-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,809] INFO [LogLoader partition=multi-broker-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,813] INFO [ProducerStateManager partition=multi-broker-topic-4] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-4\00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:24,817] INFO [LogLoader partition=multi-broker-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 4ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,822] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-4, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 40ms (2/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:24,845] INFO [LogLoader partition=multi-broker-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,846] INFO [LogLoader partition=multi-broker-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,847] INFO [ProducerStateManager partition=multi-broker-topic-5] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-5\00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:24,854] INFO [LogLoader partition=multi-broker-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,859] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-5, topicId=oWRWNyomT2C7HmfqT2tGHw, topic=multi-broker-topic, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 36ms (3/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:24,874] INFO [LogLoader partition=multi-broker-topic-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,879] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-0, topicId=aYIxc9hSSxGE5Gq1jHxC7g, topic=multi-broker-topic-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (4/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:24,889] INFO [LogLoader partition=multi-broker-topic-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,892] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-1, topicId=aYIxc9hSSxGE5Gq1jHxC7g, topic=multi-broker-topic-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (5/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:24,904] INFO [LogLoader partition=multi-broker-topic-topic-2, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,907] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-2, topicId=aYIxc9hSSxGE5Gq1jHxC7g, topic=multi-broker-topic-topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (6/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:24,918] INFO [LogLoader partition=multi-broker-topic-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,920] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-3, topicId=aYIxc9hSSxGE5Gq1jHxC7g, topic=multi-broker-topic-topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (7/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:24,931] INFO [LogLoader partition=multi-broker-topic-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,933] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-4, topicId=aYIxc9hSSxGE5Gq1jHxC7g, topic=multi-broker-topic-topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (8/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:24,944] INFO [LogLoader partition=multi-broker-topic-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,946] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-5, topicId=aYIxc9hSSxGE5Gq1jHxC7g, topic=multi-broker-topic-topic, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (9/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:24,957] INFO [LogLoader partition=multi-broker-topic-topic-6, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,960] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-broker-topic-topic-6, topicId=aYIxc9hSSxGE5Gq1jHxC7g, topic=multi-broker-topic-topic, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (10/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:24,977] INFO [LogLoader partition=multi-replica-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,978] INFO [LogLoader partition=multi-replica-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,979] INFO [ProducerStateManager partition=multi-replica-topic-0] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-0\00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:24,985] INFO [LogLoader partition=multi-replica-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:24,988] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-0, topicId=H40zMuVKTnuMcQVoka9dnQ, topic=multi-replica-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 27ms (11/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,011] INFO [LogLoader partition=multi-replica-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,012] INFO [LogLoader partition=multi-replica-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 5 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,014] INFO [ProducerStateManager partition=multi-replica-topic-1] Loading producer state from snapshot file 'SnapshotFile(offset=5, file=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-1\00000000000000000005.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:25,021] INFO [LogLoader partition=multi-replica-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 5 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,023] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-1, topicId=H40zMuVKTnuMcQVoka9dnQ, topic=multi-replica-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5) with 1 segments, local-log-start-offset 0 and log-end-offset 5 in 35ms (12/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,046] INFO [LogLoader partition=multi-replica-topic-2, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,047] INFO [LogLoader partition=multi-replica-topic-2, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,048] INFO [ProducerStateManager partition=multi-replica-topic-2] Loading producer state from snapshot file 'SnapshotFile(offset=4, file=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-2\00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:25,055] INFO [LogLoader partition=multi-replica-topic-2, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,058] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-2, topicId=H40zMuVKTnuMcQVoka9dnQ, topic=multi-replica-topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 34ms (13/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,081] INFO [LogLoader partition=multi-replica-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,081] INFO [LogLoader partition=multi-replica-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,081] INFO [ProducerStateManager partition=multi-replica-topic-3] Loading producer state from snapshot file 'SnapshotFile(offset=1, file=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-3\00000000000000000001.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:25,086] INFO [LogLoader partition=multi-replica-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,088] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-3, topicId=H40zMuVKTnuMcQVoka9dnQ, topic=multi-replica-topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments, local-log-start-offset 0 and log-end-offset 1 in 30ms (14/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,110] INFO [LogLoader partition=multi-replica-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,110] INFO [LogLoader partition=multi-replica-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,111] INFO [ProducerStateManager partition=multi-replica-topic-4] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-4\00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:25,118] INFO [LogLoader partition=multi-replica-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,121] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-4, topicId=H40zMuVKTnuMcQVoka9dnQ, topic=multi-replica-topic, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 32ms (15/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,141] INFO [LogLoader partition=multi-replica-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,141] INFO [LogLoader partition=multi-replica-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,141] INFO [ProducerStateManager partition=multi-replica-topic-5] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-5\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:25,149] INFO [LogLoader partition=multi-replica-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,152] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-5, topicId=H40zMuVKTnuMcQVoka9dnQ, topic=multi-replica-topic, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 31ms (16/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,172] INFO [LogLoader partition=multi-replica-topic-6, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,172] INFO [LogLoader partition=multi-replica-topic-6, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,173] INFO [ProducerStateManager partition=multi-replica-topic-6] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-6\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:25,180] INFO [LogLoader partition=multi-replica-topic-6, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,182] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\multi-replica-topic-6, topicId=H40zMuVKTnuMcQVoka9dnQ, topic=multi-replica-topic, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 29ms (17/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,200] INFO [LogLoader partition=test-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,206] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\test-topic-0, topicId=REe8ARNrTE2yDJNN0Y2ywA, topic=test-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 24ms (18/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,221] INFO [LogLoader partition=test-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,226] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\test-topic-3, topicId=REe8ARNrTE2yDJNN0Y2ywA, topic=test-topic, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (19/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,240] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,246] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-0, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (20/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,260] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,266] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-12, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (21/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,286] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,286] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,287] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-15\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:25,291] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 4ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,295] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-15, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 29ms (22/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,317] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,318] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\kafka\__manual-logs__\server0-logs] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,318] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'SnapshotFile(offset=4, file=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-18\00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-09-06 21:26:25,323] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\kafka\__manual-logs__\server0-logs] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,327] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-18, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 31ms (23/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,344] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,349] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-21, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 21ms (24/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,362] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,368] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-24, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 18ms (25/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,381] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,387] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-27, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (26/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,399] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,405] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-3, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 18ms (27/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,419] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,424] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-30, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 18ms (28/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,437] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,443] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-33, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (29/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,458] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,464] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-36, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 20ms (30/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,477] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,482] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-39, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (31/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,497] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,502] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-42, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (32/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,518] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,523] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-45, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 20ms (33/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,538] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,544] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-48, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 20ms (34/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,559] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,564] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-6, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (35/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,580] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\kafka\__manual-logs__\server0-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-09-06 21:26:25,586] INFO Completed load of Log(dir=D:\kafka\__manual-logs__\server0-logs\__consumer_offsets-9, topicId=bc9kl0TcQLi6LdwYPw150A, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 21ms (36/36 completed in D:\kafka\__manual-logs__\server0-logs) (kafka.log.LogManager)
[2024-09-06 21:26:25,591] INFO Loaded 36 logs in 958ms (kafka.log.LogManager)
[2024-09-06 21:26:25,594] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-09-06 21:26:25,595] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-09-06 21:26:25,679] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-09-06 21:26:25,702] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-09-06 21:26:25,719] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-09-06 21:26:25,752] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 21:26:26,004] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-09-06 21:26:26,029] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-09-06 21:26:26,036] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-09-06 21:26:26,065] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 21:26:26,066] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 21:26:26,074] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 21:26:26,074] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 21:26:26,074] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 21:26:26,088] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-09-06 21:26:26,089] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-09-06 21:26:26,153] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-09-06 21:26:26,172] INFO Stat of the created znode at /brokers/ids/0 is: 875,875,1725638186165,1725638186165,1,0,0,72120726200582153,202,0,875
 (kafka.zk.KafkaZkClient)
[2024-09-06 21:26:26,173] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:9092, czxid (broker epoch): 875 (kafka.zk.KafkaZkClient)
[2024-09-06 21:26:26,186] INFO [Controller id=1, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 21:26:26,186] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 21:26:26,192] INFO [Controller id=1, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 21:26:26,192] WARN [Controller id=1, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 21:26:26,196] INFO [Controller id=1, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 21:26:26,227] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 21:26:26,235] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 21:26:26,236] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 21:26:26,250] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,263] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,281] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 21:26:26,284] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-09-06 21:26:26,284] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-09-06 21:26:26,305] INFO [Controller id=1, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 21:26:26,305] WARN [Controller id=1, targetBrokerId=0] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 21:26:26,306] INFO [Controller id=1, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 21:26:26,334] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-09-06 21:26:26,374] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-09-06 21:26:26,399] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-09-06 21:26:26,402] INFO Awaiting socket connections on localhost:9092. (kafka.network.DataPlaneAcceptor)
[2024-09-06 21:26:26,404] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 21:26:26,405] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-09-06 21:26:26,405] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 21:26:26,406] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-09-06 21:26:26,407] INFO Kafka version: 3.8.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 21:26:26,408] INFO Kafka commitId: 771b9576b00ecf5b (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 21:26:26,408] INFO Kafka startTimeMs: 1725638186406 (org.apache.kafka.common.utils.AppInfoParser)
[2024-09-06 21:26:26,410] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-09-06 21:26:26,506] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 21:26:26,537] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,538] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 4 (kafka.cluster.Partition)
[2024-09-06 21:26:26,540] INFO [Partition multi-broker-topic-1 broker=0] Log loaded for partition multi-broker-topic-1 with initial high watermark 3 (kafka.cluster.Partition)
[2024-09-06 21:26:26,543] INFO [Partition multi-broker-topic-topic-4 broker=0] Log loaded for partition multi-broker-topic-topic-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,545] INFO [Partition multi-broker-topic-topic-0 broker=0] Log loaded for partition multi-broker-topic-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,546] INFO [Partition multi-replica-topic-1 broker=0] Log loaded for partition multi-replica-topic-1 with initial high watermark 5 (kafka.cluster.Partition)
[2024-09-06 21:26:26,546] INFO [Partition multi-replica-topic-5 broker=0] Log loaded for partition multi-replica-topic-5 with initial high watermark 3 (kafka.cluster.Partition)
[2024-09-06 21:26:26,546] INFO [Partition multi-broker-topic-4 broker=0] Log loaded for partition multi-broker-topic-4 with initial high watermark 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,546] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,547] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,547] INFO [Partition multi-broker-topic-topic-3 broker=0] Log loaded for partition multi-broker-topic-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,548] INFO [Partition multi-replica-topic-0 broker=0] Log loaded for partition multi-replica-topic-0 with initial high watermark 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,548] INFO [Partition multi-replica-topic-4 broker=0] Log loaded for partition multi-replica-topic-4 with initial high watermark 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,549] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,549] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 3 (kafka.cluster.Partition)
[2024-09-06 21:26:26,550] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,553] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,553] INFO [Partition multi-broker-topic-topic-6 broker=0] Log loaded for partition multi-broker-topic-topic-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,555] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,555] INFO [Partition multi-broker-topic-topic-2 broker=0] Log loaded for partition multi-broker-topic-topic-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,555] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,556] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,557] INFO [Partition test-topic-3 broker=0] Log loaded for partition test-topic-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,557] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,557] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,558] INFO [Partition multi-replica-topic-3 broker=0] Log loaded for partition multi-replica-topic-3 with initial high watermark 1 (kafka.cluster.Partition)
[2024-09-06 21:26:26,558] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,559] INFO [Partition multi-broker-topic-topic-5 broker=0] Log loaded for partition multi-broker-topic-topic-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,560] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,561] INFO [Partition test-topic-0 broker=0] Log loaded for partition test-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,561] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,563] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,563] INFO [Partition multi-broker-topic-topic-1 broker=0] Log loaded for partition multi-broker-topic-topic-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-09-06 21:26:26,563] INFO [Partition multi-replica-topic-2 broker=0] Log loaded for partition multi-replica-topic-2 with initial high watermark 4 (kafka.cluster.Partition)
[2024-09-06 21:26:26,563] INFO [Partition multi-replica-topic-6 broker=0] Log loaded for partition multi-replica-topic-6 with initial high watermark 3 (kafka.cluster.Partition)
[2024-09-06 21:26:26,564] INFO [Partition multi-broker-topic-5 broker=0] Log loaded for partition multi-broker-topic-5 with initial high watermark 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,566] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(multi-broker-topic-topic-0, multi-broker-topic-topic-1, multi-broker-topic-topic-2, multi-replica-topic-6, multi-replica-topic-4, multi-replica-topic-5, multi-replica-topic-2, multi-replica-topic-3, multi-replica-topic-0, multi-replica-topic-1, multi-broker-topic-topic-3, multi-broker-topic-topic-4, multi-broker-topic-topic-5, multi-broker-topic-topic-6) (kafka.server.ReplicaFetcherManager)
[2024-09-06 21:26:26,566] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 21:26:26,591] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:26:26,595] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions HashMap(multi-replica-topic-4 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),1,2), multi-broker-topic-topic-0 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),1,0), multi-replica-topic-0 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),1,2), multi-replica-topic-6 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),1,3), multi-broker-topic-topic-3 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),1,0), multi-broker-topic-topic-6 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),1,0), multi-broker-topic-topic-2 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=2, host=localhost:9094),1,0), multi-replica-topic-1 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=2, host=localhost:9094),1,5)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 21:26:26,599] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:26:26,601] INFO [UnifiedLog partition=multi-broker-topic-topic-0, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 21:26:26,602] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions HashMap(multi-replica-topic-2 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=1, host=localhost:9093),1,4), multi-broker-topic-topic-1 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=1, host=localhost:9093),1,0), multi-replica-topic-3 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=1, host=localhost:9093),1,1), multi-broker-topic-topic-4 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=1, host=localhost:9093),1,0), multi-broker-topic-topic-5 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=1, host=localhost:9093),1,0), multi-replica-topic-5 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=1, host=localhost:9093),1,3)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 21:26:26,603] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:26:26,602] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:26:26,603] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition multi-broker-topic-topic-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:26:26,604] INFO [UnifiedLog partition=multi-broker-topic-topic-2, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 21:26:26,604] INFO [UnifiedLog partition=multi-broker-topic-topic-1, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 21:26:26,604] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:26:26,605] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition multi-broker-topic-topic-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:26:26,605] INFO [UnifiedLog partition=multi-broker-topic-topic-3, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 21:26:26,605] INFO [UnifiedLog partition=multi-broker-topic-topic-4, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 21:26:26,606] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition multi-broker-topic-topic-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:26:26,606] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition multi-broker-topic-topic-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:26:26,607] INFO [UnifiedLog partition=multi-broker-topic-topic-6, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 21:26:26,607] INFO [UnifiedLog partition=multi-broker-topic-topic-5, dir=D:\kafka\__manual-logs__\server0-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 21:26:26,634] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, test-topic-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, multi-broker-topic-4, __consumer_offsets-48, multi-broker-topic-5, test-topic-0, __consumer_offsets-39, __consumer_offsets-12, multi-broker-topic-1, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2024-09-06 21:26:26,660] INFO [NodeToControllerChannelManager id=1 name=alter-partition] Client requested disconnect from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 21:26:26,661] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 21:26:26,676] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Client requested disconnect from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-09-06 21:26:26,680] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-09-06 21:26:26,685] INFO [Partition multi-replica-topic-5 broker=1] ISR updated to 1,2,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,697] INFO [Partition multi-replica-topic-6 broker=2] ISR updated to 2,1,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,699] INFO [Partition multi-replica-topic-2 broker=1] ISR updated to 1,2,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,699] INFO [Partition multi-replica-topic-3 broker=1] ISR updated to 1,2,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,700] INFO [Partition multi-broker-topic-topic-1 broker=1] ISR updated to 1,2,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,700] INFO [Partition multi-broker-topic-topic-4 broker=1] ISR updated to 1,2,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,700] INFO [Partition multi-broker-topic-topic-5 broker=1] ISR updated to 1,2,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,710] INFO [Partition multi-replica-topic-4 broker=2] ISR updated to 2,1,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,710] INFO [Partition multi-broker-topic-topic-0 broker=2] ISR updated to 2,1,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,711] INFO [Partition multi-replica-topic-0 broker=2] ISR updated to 2,1,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,711] INFO [Partition multi-replica-topic-1 broker=2] ISR updated to 2,1,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,711] INFO [Partition multi-broker-topic-topic-2 broker=2] ISR updated to 2,1,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,711] INFO [Partition multi-broker-topic-topic-3 broker=2] ISR updated to 2,1,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,712] INFO [Partition multi-broker-topic-topic-6 broker=2] ISR updated to 2,1,0  and version updated to 2 (kafka.cluster.Partition)
[2024-09-06 21:26:26,747] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,747] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,749] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,749] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,751] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,752] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,753] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,753] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,754] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,754] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,755] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,755] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,756] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,756] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,756] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 7 milliseconds for epoch 8, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,756] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,760] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,761] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,762] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,762] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,766] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,769] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,769] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,771] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,771] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,771] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,772] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,772] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,772] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,773] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,782] INFO Loaded member MemberMetadata(memberId=console-consumer-303a0f9b-ecbc-4ca3-b4fe-fcb9480252b3, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-90882 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 21:26:26,787] INFO Loaded member MemberMetadata(memberId=console-consumer-4ca4fa6a-ea90-4a41-b9d1-cc37dbfea408, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-90224 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 21:26:26,788] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-90224 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:26:26,793] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 42 milliseconds for epoch 8, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,794] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 42 milliseconds for epoch 8, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,794] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 40 milliseconds for epoch 8, of which 40 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,794] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 39 milliseconds for epoch 8, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,795] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 40 milliseconds for epoch 8, of which 40 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,795] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 39 milliseconds for epoch 8, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,796] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 39 milliseconds for epoch 8, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,799] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 41 milliseconds for epoch 8, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,799] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 39 milliseconds for epoch 8, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,800] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 39 milliseconds for epoch 8, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,800] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 38 milliseconds for epoch 8, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 32 milliseconds for epoch 8, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 30 milliseconds for epoch 8, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,804] INFO Loaded member MemberMetadata(memberId=console-consumer-40f12e9a-e3ab-491b-8602-b1d8f8a145f4, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-96964 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-09-06 21:26:26,805] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 33 milliseconds for epoch 8, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,805] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 33 milliseconds for epoch 8, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:26:26,805] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 32 milliseconds for epoch 8, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:27:11,809] INFO [GroupCoordinator 0]: Member console-consumer-4ca4fa6a-ea90-4a41-b9d1-cc37dbfea408 in group console-consumer-90224 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:27:11,821] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-90224 in state PreparingRebalance with old generation 1 (__consumer_offsets-18) (reason: removing member console-consumer-4ca4fa6a-ea90-4a41-b9d1-cc37dbfea408 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:27:11,827] INFO [GroupCoordinator 0]: Group console-consumer-90224 with generation 2 is now empty (__consumer_offsets-18) (kafka.coordinator.group.GroupCoordinator)
[2024-09-06 21:30:16,691] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(multi-replica-topic-6, multi-replica-topic-3, multi-replica-topic-0, multi-broker-topic-topic-2, multi-broker-topic-topic-5) (kafka.server.ReplicaFetcherManager)
[2024-09-06 21:30:16,692] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(multi-replica-topic-6, multi-replica-topic-3, multi-replica-topic-0, multi-broker-topic-topic-2, multi-broker-topic-topic-5) (kafka.server.ReplicaFetcherManager)
[2024-09-06 21:30:16,703] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(multi-replica-topic-0, multi-replica-topic-3, multi-replica-topic-6, multi-broker-topic-topic-5, multi-broker-topic-topic-2) (kafka.server.ReplicaFetcherManager)
[2024-09-06 21:30:16,705] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions HashMap(multi-replica-topic-0 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),2,2), multi-replica-topic-3 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),2,1), multi-replica-topic-6 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),2,3), multi-broker-topic-topic-5 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=0, host=localhost:9092),2,0), multi-broker-topic-topic-2 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=0, host=localhost:9092),2,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 21:30:16,705] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:30:16,706] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition multi-broker-topic-topic-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:30:16,706] INFO [UnifiedLog partition=multi-broker-topic-topic-2, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 21:30:16,707] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:30:16,707] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions HashMap(multi-replica-topic-0 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),2,2), multi-replica-topic-3 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),2,1), multi-replica-topic-6 -> InitialFetchState(Some(H40zMuVKTnuMcQVoka9dnQ),BrokerEndPoint(id=0, host=localhost:9092),2,3), multi-broker-topic-topic-5 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=0, host=localhost:9092),2,0), multi-broker-topic-topic-2 -> InitialFetchState(Some(aYIxc9hSSxGE5Gq1jHxC7g),BrokerEndPoint(id=0, host=localhost:9092),2,0)) (kafka.server.ReplicaFetcherManager)
[2024-09-06 21:30:16,707] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition multi-broker-topic-topic-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:30:16,708] INFO [UnifiedLog partition=multi-broker-topic-topic-5, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-09-06 21:30:16,762] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition multi-replica-topic-0 with TruncationState(offset=2, completed=true) due to leader epoch and offset EpochEndOffset(errorCode=0, partition=0, leaderEpoch=0, endOffset=2) (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:30:16,763] INFO [UnifiedLog partition=multi-replica-topic-0, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.UnifiedLog)
[2024-09-06 21:30:17,804] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition multi-replica-topic-6 with TruncationState(offset=3, completed=true) due to leader epoch and offset EpochEndOffset(errorCode=0, partition=6, leaderEpoch=0, endOffset=3) (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:30:17,805] INFO [UnifiedLog partition=multi-replica-topic-6, dir=D:\kafka\__manual-logs__\server2-logs] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.UnifiedLog)
[2024-09-06 21:30:17,806] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition multi-replica-topic-3 with TruncationState(offset=1, completed=true) due to leader epoch and offset EpochEndOffset(errorCode=0, partition=3, leaderEpoch=0, endOffset=1) (kafka.server.ReplicaFetcherThread)
[2024-09-06 21:30:17,806] INFO [UnifiedLog partition=multi-replica-topic-3, dir=D:\kafka\__manual-logs__\server1-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.UnifiedLog)
[2024-09-06 21:36:26,283] INFO [GroupMetadataManager brokerId=0] Group console-consumer-90224 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2024-09-06 21:36:26,781] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2024-09-06 21:36:26,871] INFO [NodeToControllerChannelManager id=1 name=alter-partition] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
